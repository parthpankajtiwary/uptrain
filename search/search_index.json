{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> <p>An open-source framework to evaluate, test and monitor LLM applications</p> </p> <p> Docs  - Slack Community - Bug Report - Feature Request </p> <p>UpTrain is a Python framework that ensures your LLM applications are performing reliably by allowing users to check aspects such as correctness, structural integrity, bias, hallucination, etc. UpTrain can be used to:</p> <p>1) Validate model's response and safeguard your users against hallucinations, bias, incorrect output formats, etc. 2) Experiment across multiple model providers, prompt templates, and quantify model's performance. 3) Monitor your model's performance in production and protect yourself against unwanted drifts</p>"},{"location":"#key-features","title":"Key Features \ud83d\udca1","text":"<ul> <li>ChatGPT Grading - Utilize LLMs to grade your model outputs.</li> <li>Custom Grading Checks - Write your custom grading prompts.</li> <li>Embeddings Similarity Check - Compute cosine similarity between prompt and response embeddings</li> <li>Output Validation - Safeguard your users against inappropriate responses</li> <li>Prompt A/B Testing - Experiment across multiple prompts and compare them quantatively.</li> <li>UMAP Visualization and Clustering - Visualize your embedding space using tools like UMAP and t-SNE.</li> <li>Hallucination Checks - Use metrics like custom grading, text similarity, and embedding similarity to check for hallucinations.</li> <li>Toxic Keywords Checks - Make sure your model outputs are not biased or contain toxic keywords.</li> <li>Feature Slicing - Built-in pivoting functionalities for data dice and slice to pinpoint low-performing cohorts.</li> <li>Realtime Dashboards - Monitor your model's performance in realtime.</li> </ul>"},{"location":"#get-started","title":"Get started \ud83d\ude4c","text":"<p>To run it on your machine, checkout the Quickstart tutorial:</p>"},{"location":"#install-the-package-through-pip","title":"Install the package through pip:","text":"<pre><code>pip install uptrain\n</code></pre> <p>Note: Uptrain uses commonly used python libraries like openai-evals and sentence-transformers. To make sure, all the functionalities work, use the <code>uptrain-add</code> command to install the full version of the package.</p> <pre><code>uptrain-add --feature full\n</code></pre>"},{"location":"#how-to-use-uptrain-in-4-simple-steps","title":"How to use UpTrain in 4 simple steps:","text":"<p>Say we want to plot a line chart showing whether our model's responses contain any grammatical mistakes or not.</p> <pre><code># Step 1: Choose and create the appropriate operator from UpTrain\ngrammar_score = GrammarScore(\n  col_in_text = \"model_response\",       # input column name (from dataset)\n  col_out = \"grammar_score\"             # desired output column name\n)\n\n# Step 2: Create a check with the operators and the required plots as arguments \ngrammar_check = Check(\n  operators = [grammar_score],\n  plots = LineChart(y = \"grammar_score\")\n)\n\n# Step 3: Create a CheckSet with the checks and data source as arguments\ncheckset = CheckSet(\n    checks = [grammar_check]\n    source = JsonReader(fpath = '...')\n)\n\n# Step 4: Set up and run the CheckSet\ncheckset.setup(Settings(openai_api_key = '...'))\ncheckset.run(dataset)\n</code></pre>"},{"location":"#integrations","title":"Integrations","text":"Eval Frameworks LLM Providers LLM Packages Serving frameworks OpenAI Evals \u2705 GPT-3.5-turbo \u2705 Langchain \ud83d\udd1c HuggingFace \ud83d\udd1c EleutherAI LM Eval \ud83d\udd1c GPT-4 \u2705 Llama Index \ud83d\udd1c Replicate \ud83d\udd1c BIG-Bench \ud83d\udd1c Claude \ud83d\udd1c AutoGPT \ud83d\udd1c Cohere \ud83d\udd1c"},{"location":"#uptrain-in-action","title":"UpTrain in Action","text":""},{"location":"#experimentation","title":"Experimentation","text":"<p>You can use the UpTrain framework to run and compare LLM responses for different prompts, models, LLM chains, etc. Check out the experimentation tutorial to learn more.</p>"},{"location":"#validation","title":"Validation","text":"<p>You can use the UpTrain Validation Manager to define checks, retry logic and validate your LLM responses before showing it to your users. Check out the tutorial here.</p>"},{"location":"#monitoring","title":"Monitoring","text":"<p>You can use the UpTrain framework to continuously monitor your model's performance and get real-time insights on how well it is doing on a variety of evaluation metrics. Check out the monitoring tutorial to learn more.</p>"},{"location":"#why-uptrain","title":"Why UpTrain \ud83e\udd14?","text":"<p>Large language models are trained over billions of data points and perform really well over a wide variety of tasks. But one thing these models are not good at is being deterministic. Even with the most well-crafted prompts, the model can misbehave for certain inputs, be it hallucinations, wrong output structure, toxic or biased response, irrelevant response, and error modes can be immense. </p> <p>To ensure your LLM applications work reliably and correctly, UpTrain makes it easy for developers to evaluate the responses of their applications on multiple criteria. UpTrain's evaluation framework can be used to:</p> <p>1) Validate (and correct) the response of the model before showing it to the user 2) Get quantitative measures to experiment across multiple prompts, model providers, etc. 3) Do unit testing to ensure no buggy prompt or code gets pushed into your production 4) Monitor your LLM applications in real time and understand when they are going wrong in order to fix them before users complain.</p> <p>We are constantly working to make UpTrain better. Want a new feature or need any integrations? Feel free to create an issue or contribute directly to the repository.</p>"},{"location":"#license","title":"License \ud83d\udcbb","text":"<p>This repo is published under Apache 2.0 license. We are also working towards adding a hosted offering to make setting off eval runs easier - please fill this form to get a waitlist slot.</p>"},{"location":"#stay-updated","title":"Stay Updated \u260e\ufe0f","text":"<p>We are continuously adding tons of features and use cases. Please support us by giving the project a star \u2b50!</p>"},{"location":"#provide-feedback-harsher-the-better","title":"Provide feedback (Harsher the better \ud83d\ude09)","text":"<p>We are building UpTrain in public. Help us improve by giving your feedback here.</p>"},{"location":"#contributors","title":"Contributors \ud83d\udda5\ufe0f","text":"<p>We welcome contributions to UpTrain. Please see our contribution guide for details.</p> <p> </p>"},{"location":"framework/Check/","title":"Check","text":"<p>A simple check that runs the given list of table operators in sequence.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the check.</p> <code>operators</code> <code>list[TableOp]</code> <p>A list of operators to run in sequence on the input data. The output of each operator is passed as input to the next operator.</p> <code>plots</code> <code>list[Operator]</code> <p>How to plot the output of the check.</p> Source code in <code>uptrain/framework/checks.py</code> <pre><code>class Check:\n\"\"\"A simple check that runs the given list of table operators in sequence.\n\n    Attributes:\n        name (str): Name of the check.\n        operators (list[TableOp]): A list of operators to run in sequence on the input data. The output of each\n            operator is passed as input to the next operator.\n        plots (list[Operator]): How to plot the output of the check.\n    \"\"\"\n\n    name: str\n    operators: list[Operator]\n    plots: list[Operator]\n\n    def __init__(\n        self,\n        name: str,\n        operators: list[Operator],\n        plots: list[Operator] | None = None,\n    ):\n        self.name = name\n        self.operators = operators\n        self.plots = plots if plots is not None else []\n\n    def setup(self, settings: \"Settings\"):\n        self._settings = settings\n\n        # no need to add the plot operator to the dag, since it's run later\n        self._op_dag = OperatorDAG(name=self.name)\n        for i, op in enumerate(self.operators):\n            if i == 0:\n                deps = []\n            else:\n                deps = [f\"operator_{i-1}\"]\n            self._op_dag.add_step(f\"operator_{i}\", op, deps=deps)\n        self._op_dag.setup(settings)\n\n        return self\n\n    def run(self, data: pl.DataFrame | None = None) -&gt; pl.DataFrame | None:\n\"\"\"Run this check on the given data.\"\"\"\n        node_inputs = {\"operator_0\": data}\n\n        if len(self.operators):\n            # pick output from the last op in the sequence\n            name_final_node = f\"operator_{len(self.operators) - 1}\"\n            node_outputs = self._op_dag.run(\n                node_inputs=node_inputs,\n                output_nodes=[name_final_node],\n            )\n            return node_outputs[name_final_node]\n        else:\n            return data\n\n    def dict(self) -&gt; dict:\n\"\"\"Serialize this check to a dict.\"\"\"\n        return {\n            \"name\": self.name,\n            \"operators\": [to_py_types(op) for op in self.operators],\n            \"plots\": [to_py_types(op) for op in self.plots],\n        }  # serializes only the attributes of the class, like pydantic models\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; \"Check\":\n\"\"\"Deserialize a check from a dict of its parameters.\"\"\"\n        operators = [deserialize_operator(op) for op in data[\"operators\"]]\n        plots = [deserialize_operator(op) for op in data[\"plots\"]]\n        return cls(name=data[\"name\"], operators=operators, plots=plots)  # type: ignore\n</code></pre>"},{"location":"framework/Check/#uptrain.framework.checks.Check.dict","title":"<code>dict()</code>","text":"<p>Serialize this check to a dict.</p> Source code in <code>uptrain/framework/checks.py</code> <pre><code>def dict(self) -&gt; dict:\n\"\"\"Serialize this check to a dict.\"\"\"\n    return {\n        \"name\": self.name,\n        \"operators\": [to_py_types(op) for op in self.operators],\n        \"plots\": [to_py_types(op) for op in self.plots],\n    }  # serializes only the attributes of the class, like pydantic models\n</code></pre>"},{"location":"framework/Check/#uptrain.framework.checks.Check.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Deserialize a check from a dict of its parameters.</p> Source code in <code>uptrain/framework/checks.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; \"Check\":\n\"\"\"Deserialize a check from a dict of its parameters.\"\"\"\n    operators = [deserialize_operator(op) for op in data[\"operators\"]]\n    plots = [deserialize_operator(op) for op in data[\"plots\"]]\n    return cls(name=data[\"name\"], operators=operators, plots=plots)  # type: ignore\n</code></pre>"},{"location":"framework/Check/#uptrain.framework.checks.Check.run","title":"<code>run(data=None)</code>","text":"<p>Run this check on the given data.</p> Source code in <code>uptrain/framework/checks.py</code> <pre><code>def run(self, data: pl.DataFrame | None = None) -&gt; pl.DataFrame | None:\n\"\"\"Run this check on the given data.\"\"\"\n    node_inputs = {\"operator_0\": data}\n\n    if len(self.operators):\n        # pick output from the last op in the sequence\n        name_final_node = f\"operator_{len(self.operators) - 1}\"\n        node_outputs = self._op_dag.run(\n            node_inputs=node_inputs,\n            output_nodes=[name_final_node],\n        )\n        return node_outputs[name_final_node]\n    else:\n        return data\n</code></pre>"},{"location":"framework/CheckSet/","title":"CheckSet","text":"<p>Container for a set of checks to run together. This is the entrypoint to Uptrain for users.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>Operator</code> <p>The source operator to run. Specifies where to get the data from.</p> <code>preprocessors</code> <code>list[TableOp]</code> <p>A list of operators to run on the input data before running the checks.</p> <code>checks</code> <code>list[Check]</code> <p>The set of checks to run on the input data.</p> Source code in <code>uptrain/framework/checks.py</code> <pre><code>class CheckSet:\n\"\"\"Container for a set of checks to run together. This is the entrypoint to Uptrain for users.\n\n    Attributes:\n        source (Operator): The source operator to run. Specifies where to get the data from.\n        preprocessors (list[TableOp]): A list of operators to run on the input data before running the checks.\n        checks (list[Check]): The set of checks to run on the input data.\n    \"\"\"\n\n    source: Operator\n    checks: list[Check]\n    preprocessors: list[TransformOp]\n\n    def __init__(\n        self,\n        source: Operator,\n        checks: list[t.Any],\n        preprocessors: list[TransformOp] | None = None,\n    ):\n        self.source = source\n        self.checks = checks\n        self.preprocessors = preprocessors if preprocessors is not None else []\n\n        # verify all checks have different names\n        check_names = [check.name for check in checks]\n        assert len(set(check_names)) == len(check_names), \"Duplicate check names\"\n        for check in checks:\n            assert isinstance(check, Check), \"Each check must be an instance of Check\"\n\n    def setup(self, settings: Settings):\n\"\"\"Create the logs directory, or clear it if it already exists. Also, persist the\n        evaluation config.\n        \"\"\"\n        self._settings = settings\n        logs_dir = self._settings.logs_folder\n        if not os.path.exists(logs_dir):\n            os.makedirs(logs_dir)\n        else:\n            clear_directory(logs_dir)\n\n        logger.info(f\"Uptrain Logs directory: {logs_dir}\")\n\n        # persist the check-set as well as the corresponding settings\n        self.serialize(os.path.join(logs_dir, \"config.json\"))\n        self._settings.serialize(os.path.join(logs_dir, \"settings.json\"))\n\n        self.source.setup(self._settings)\n        for preprocessor in self.preprocessors:\n            preprocessor.setup(self._settings)\n        for check in self.checks:\n            check.setup(self._settings)\n        return self\n\n    def run(self):\n\"\"\"Run all checks in this set.\"\"\"\n        from uptrain.operators import JsonWriter\n\n        source_output = self.source.run()[\"output\"]\n        if source_output is None:\n            raise RuntimeError(\"Dataset read from the source is: None\")\n        if len(source_output) == 0:\n            raise RuntimeError(\"Dataset read from the source is: empty\")\n\n        if len(self.preprocessors) &gt; 0:\n            for preprocessor in self.preprocessors:\n                source_output = preprocessor.run(source_output)[\"output\"]\n                assert source_output is not None, \"Output of preprocessor is None\"\n\n            # persist the preprocessed input for debugging\n            JsonWriter(\n                fpath=os.path.join(\n                    self._settings.logs_folder, \"preprocessed_input.jsonl\"\n                )\n            ).setup(self._settings).run(source_output)\n\n        for check in self.checks:\n            check_output = check.run(source_output)\n            assert check_output is not None, f\"Output of check {check.name} is None\"\n            self._get_sink_for_check(self._settings, check).run(check_output)\n\n    @staticmethod\n    def _get_sink_for_check(settings: Settings, check: Check):\n\"\"\"Get the sink operator for this check.\"\"\"\n        from uptrain.operators import JsonWriter\n\n        fname = check.name.replace(\" \", \"_\") + \".jsonl\"\n        return JsonWriter(fpath=os.path.join(settings.logs_folder, fname))\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; \"CheckSet\":\n        checks = [Check.from_dict(check) for check in data.get(\"checks\", [])]\n        return cls(\n            source=deserialize_operator(data[\"source\"]),\n            preprocessors=[\n                deserialize_operator(op) for op in data.get(\"preprocessors\", [])\n            ],  # type: ignore\n            checks=checks,\n        )\n\n    def dict(self) -&gt; dict:\n        return {\n            \"source\": to_py_types(self.source),\n            \"preprocessors\": [to_py_types(op) for op in self.preprocessors],\n            \"checks\": [check.dict() for check in self.checks],\n        }\n\n    @classmethod\n    def deserialize(cls, fpath: str) -&gt; \"CheckSet\":\n        with open(fpath, \"r\") as f:\n            return cls.from_dict(jsonload(f))\n\n    def serialize(self, fpath: t.Optional[str] = None):\n\"\"\"Serialize this check set along with the run settings to a JSON file.\"\"\"\n        if fpath is None:\n            fpath = os.path.join(self._settings.logs_folder, \"config.json\")\n\n        with open(fpath, \"w\") as f:\n            jsondump(self.dict(), f)\n</code></pre>"},{"location":"framework/CheckSet/#uptrain.framework.checks.CheckSet.run","title":"<code>run()</code>","text":"<p>Run all checks in this set.</p> Source code in <code>uptrain/framework/checks.py</code> <pre><code>def run(self):\n\"\"\"Run all checks in this set.\"\"\"\n    from uptrain.operators import JsonWriter\n\n    source_output = self.source.run()[\"output\"]\n    if source_output is None:\n        raise RuntimeError(\"Dataset read from the source is: None\")\n    if len(source_output) == 0:\n        raise RuntimeError(\"Dataset read from the source is: empty\")\n\n    if len(self.preprocessors) &gt; 0:\n        for preprocessor in self.preprocessors:\n            source_output = preprocessor.run(source_output)[\"output\"]\n            assert source_output is not None, \"Output of preprocessor is None\"\n\n        # persist the preprocessed input for debugging\n        JsonWriter(\n            fpath=os.path.join(\n                self._settings.logs_folder, \"preprocessed_input.jsonl\"\n            )\n        ).setup(self._settings).run(source_output)\n\n    for check in self.checks:\n        check_output = check.run(source_output)\n        assert check_output is not None, f\"Output of check {check.name} is None\"\n        self._get_sink_for_check(self._settings, check).run(check_output)\n</code></pre>"},{"location":"framework/CheckSet/#uptrain.framework.checks.CheckSet.serialize","title":"<code>serialize(fpath=None)</code>","text":"<p>Serialize this check set along with the run settings to a JSON file.</p> Source code in <code>uptrain/framework/checks.py</code> <pre><code>def serialize(self, fpath: t.Optional[str] = None):\n\"\"\"Serialize this check set along with the run settings to a JSON file.\"\"\"\n    if fpath is None:\n        fpath = os.path.join(self._settings.logs_folder, \"config.json\")\n\n    with open(fpath, \"w\") as f:\n        jsondump(self.dict(), f)\n</code></pre>"},{"location":"framework/CheckSet/#uptrain.framework.checks.CheckSet.setup","title":"<code>setup(settings)</code>","text":"<p>Create the logs directory, or clear it if it already exists. Also, persist the evaluation config.</p> Source code in <code>uptrain/framework/checks.py</code> <pre><code>def setup(self, settings: Settings):\n\"\"\"Create the logs directory, or clear it if it already exists. Also, persist the\n    evaluation config.\n    \"\"\"\n    self._settings = settings\n    logs_dir = self._settings.logs_folder\n    if not os.path.exists(logs_dir):\n        os.makedirs(logs_dir)\n    else:\n        clear_directory(logs_dir)\n\n    logger.info(f\"Uptrain Logs directory: {logs_dir}\")\n\n    # persist the check-set as well as the corresponding settings\n    self.serialize(os.path.join(logs_dir, \"config.json\"))\n    self._settings.serialize(os.path.join(logs_dir, \"settings.json\"))\n\n    self.source.setup(self._settings)\n    for preprocessor in self.preprocessors:\n        preprocessor.setup(self._settings)\n    for check in self.checks:\n        check.setup(self._settings)\n    return self\n</code></pre>"},{"location":"framework/Remote/","title":"Remote","text":"<p>This module implements a simple client that can be used to schedule unit-tests/evaluations  on the UpTrain server.</p>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient","title":"<code>APIClient</code>","text":"Source code in <code>uptrain/framework/remote.py</code> <pre><code>class APIClient:\n    base_url: str\n    client: httpx.Client\n\n    def __init__(self, settings: Settings) -&gt; None:\n        server_url = settings.check_and_get(\"uptrain_server_url\")\n        api_key = settings.check_and_get(\"uptrain_access_token\")\n        self.base_url = server_url.rstrip(\"/\") + \"/api/public\"\n        self.client = httpx.Client(headers={\"uptrain-access-token\": api_key})\n\n    def check_auth(self):\n\"\"\"Ping the server to check if the client is authenticated.\"\"\"\n        url = f\"{self.base_url}/auth\"\n        try:\n            response = self.client.get(url)\n            return raise_or_return(response)\n        except httpx.ConnectError as e:\n            raise RuntimeError(\n                f\"Failed to connect to the Uptrain server at {self.base_url}\"\n            ) from e\n\n    def add_dataset(self, name: str, fpath: str):\n        url = f\"{self.base_url}/dataset\"\n        with open(fpath, \"rb\") as file:\n            files = {\"data_file\": (name, file, \"application/octet-stream\")}\n            response = self.client.post(url, data={\"name\": name}, files=files)\n        return raise_or_return(response)\n\n    def get_dataset(self, name: str, version: t.Optional[int] = None):\n        url = f\"{self.base_url}/dataset\"\n        params: dict = {\"name\": name}\n        if version is not None:\n            params[\"version\"] = version\n        response = self.client.get(url, params=params)\n        return raise_or_return(response)\n\n    def list_datasets(self, skip: int = 0, limit: int = 100):\n        url = f\"{self.base_url}/datasets\"\n        params = {\"skip\": skip, \"limit\": limit}\n        response = self.client.get(url, params=params)\n        return raise_or_return(response)\n\n    def add_checkset(self, name: str, checkset: CheckSet, settings: Settings):\n        url = f\"{self.base_url}/checkset\"\n        response = self.client.post(\n            url,\n            json={\"name\": name, \"config\": checkset.dict(), \"settings\": settings.dict()},\n        )\n        return raise_or_return(response)\n\n    def get_checkset(self, name: str, version: t.Optional[int] = None):\n        url = f\"{self.base_url}/checkset\"\n        params: dict = {\"name\": name}\n        if version is not None:\n            params[\"version\"] = version\n        response = self.client.get(url, params=params)\n        return raise_or_return(response)\n\n    def list_checksets(self, skip: int = 0, limit: int = 10):\n        url = f\"{self.base_url}/checksets\"\n        params = {\"skip\": skip, \"limit\": limit}\n        response = self.client.get(url, params=params)\n        return raise_or_return(response)\n\n    def add_experiment(\n        self,\n        name: str,\n        checkset: CheckSet,\n        experiment_args: ExperimentArgs,\n        settings: Settings,\n    ):\n        preprocessors = experiment_args._get_preprocessors()\n        modified_checks = experiment_args._modify_checks(checkset.checks)\n        modified_checkset = CheckSet(\n            source=checkset.source, checks=modified_checks, preprocessors=preprocessors\n        )\n        url = f\"{self.base_url}/checkset\"\n        response = self.client.post(\n            url,\n            json={\n                \"name\": name,\n                \"config\": modified_checkset.dict(),\n                \"settings\": settings.dict(),\n            },\n        )\n        return raise_or_return(response)\n\n    def add_run(self, dataset: str, checkset: str) -&gt; dict:\n\"\"\"Schedules an evaluation on the server. Specify the dataset and checkset to use.\n\n        Args:\n            dataset: name of the dataset to use\n            checkset: name of the checkset to use\n\n        Returns:\n            run: information about the run along with a unique identifier.\n        \"\"\"\n        url = f\"{self.base_url}/run\"\n        response = self.client.post(\n            url, json={\"dataset\": dataset, \"checkset\": checkset}\n        )\n        return raise_or_return(response)\n\n    def get_run(self, run_id: str):\n\"\"\"Get the status of a run.\n\n        Args:\n            run_id: unique identifier for the run.\n\n        Returns:\n            run: information about the run along with a unique identifier.\n        \"\"\"\n        url = f\"{self.base_url}/run/{run_id}\"\n        response = self.client.get(url)\n        return raise_or_return(response)\n\n    def download_run_result(self, run_id: str, check_name: str, fpath: str) -&gt; None:\n\"\"\"Get the results of a run.\n\n        Args:\n            run_id: unique identifier for the run.\n            check_name: name of the check to get results for.\n            fpath: path to save the results to.\n        \"\"\"\n        url = f\"{self.base_url}/run/{run_id}/results\"\n        params: dict = {\"check_name\": check_name}\n        with self.client.stream(\"GET\", url, params=params) as response:\n            if not response.is_success:\n                logger.error(response.text)\n                response.raise_for_status()\n            else:\n                with open(fpath, \"wb\") as download_file:\n                    for chunk in response.iter_bytes():\n                        download_file.write(chunk)\n\n    def list_runs(self, num: int = 10, only_completed: bool = False):\n\"\"\"List all the runs on the server.\n\n        - filter by scheduled/completed/in-process?\n        \"\"\"\n        url = f\"{self.base_url}/runs\"\n        params: dict = {\"num\": num}\n        if only_completed:\n            params[\"status\"] = \"completed\"\n        response = self.client.get(url, params=params)\n        return raise_or_return(response)\n\n    def add_daily_schedule(self, checkset: str, start_on: str) -&gt; dict:\n\"\"\"Schedules a periodic evaluation on the server. Specify the checkset to run against it.\n\n        Args:\n            checkset: name of the checkset to use\n            start_on: date to start the schedule on\n\n        Returns:\n            run: information about the schedule along with a unique identifier.\n        \"\"\"\n        url = f\"{self.base_url}/schedule\"\n        response = self.client.post(\n            url, json={\"checkset\": checkset, \"start_on\": start_on}\n        )\n        return raise_or_return(response)\n\n    def get_schedule(self, schedule_id: str) -&gt; str:\n\"\"\"Get the status of a schedule.\n\n        Args:\n            schedule_id: unique identifier for the run.\n\n        Returns:\n            run: information about the schedule along with a unique identifier.\n        \"\"\"\n        url = f\"{self.base_url}/schedule/{schedule_id}\"\n        response = self.client.get(url)\n        return raise_or_return(response)\n\n    def remove_schedule(self, schedule_id: str) -&gt; str:\n\"\"\"Remove a schedule.\n\n        Args:\n            schedule_id: unique identifier for the run.\n\n        Returns:\n            run: information about the schedule along with a unique identifier.\n        \"\"\"\n        url = f\"{self.base_url}/schedule/{schedule_id}\"\n        response = self.client.delete(url)\n        return raise_or_return(response)\n\n    def list_schedules(self, num: int = 10, active_only: bool = True):\n\"\"\"List all the schedules on the server.\"\"\"\n        url = f\"{self.base_url}/schedules\"\n        params: dict = {\"num\": num, \"active_only\": active_only}\n        response = self.client.get(url, params=params)\n        return raise_or_return(response)\n</code></pre>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient.add_daily_schedule","title":"<code>add_daily_schedule(checkset, start_on)</code>","text":"<p>Schedules a periodic evaluation on the server. Specify the checkset to run against it.</p> <p>Parameters:</p> Name Type Description Default <code>checkset</code> <code>str</code> <p>name of the checkset to use</p> required <code>start_on</code> <code>str</code> <p>date to start the schedule on</p> required <p>Returns:</p> Name Type Description <code>run</code> <code>dict</code> <p>information about the schedule along with a unique identifier.</p> Source code in <code>uptrain/framework/remote.py</code> <pre><code>def add_daily_schedule(self, checkset: str, start_on: str) -&gt; dict:\n\"\"\"Schedules a periodic evaluation on the server. Specify the checkset to run against it.\n\n    Args:\n        checkset: name of the checkset to use\n        start_on: date to start the schedule on\n\n    Returns:\n        run: information about the schedule along with a unique identifier.\n    \"\"\"\n    url = f\"{self.base_url}/schedule\"\n    response = self.client.post(\n        url, json={\"checkset\": checkset, \"start_on\": start_on}\n    )\n    return raise_or_return(response)\n</code></pre>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient.add_run","title":"<code>add_run(dataset, checkset)</code>","text":"<p>Schedules an evaluation on the server. Specify the dataset and checkset to use.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>name of the dataset to use</p> required <code>checkset</code> <code>str</code> <p>name of the checkset to use</p> required <p>Returns:</p> Name Type Description <code>run</code> <code>dict</code> <p>information about the run along with a unique identifier.</p> Source code in <code>uptrain/framework/remote.py</code> <pre><code>def add_run(self, dataset: str, checkset: str) -&gt; dict:\n\"\"\"Schedules an evaluation on the server. Specify the dataset and checkset to use.\n\n    Args:\n        dataset: name of the dataset to use\n        checkset: name of the checkset to use\n\n    Returns:\n        run: information about the run along with a unique identifier.\n    \"\"\"\n    url = f\"{self.base_url}/run\"\n    response = self.client.post(\n        url, json={\"dataset\": dataset, \"checkset\": checkset}\n    )\n    return raise_or_return(response)\n</code></pre>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient.check_auth","title":"<code>check_auth()</code>","text":"<p>Ping the server to check if the client is authenticated.</p> Source code in <code>uptrain/framework/remote.py</code> <pre><code>def check_auth(self):\n\"\"\"Ping the server to check if the client is authenticated.\"\"\"\n    url = f\"{self.base_url}/auth\"\n    try:\n        response = self.client.get(url)\n        return raise_or_return(response)\n    except httpx.ConnectError as e:\n        raise RuntimeError(\n            f\"Failed to connect to the Uptrain server at {self.base_url}\"\n        ) from e\n</code></pre>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient.download_run_result","title":"<code>download_run_result(run_id, check_name, fpath)</code>","text":"<p>Get the results of a run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>unique identifier for the run.</p> required <code>check_name</code> <code>str</code> <p>name of the check to get results for.</p> required <code>fpath</code> <code>str</code> <p>path to save the results to.</p> required Source code in <code>uptrain/framework/remote.py</code> <pre><code>def download_run_result(self, run_id: str, check_name: str, fpath: str) -&gt; None:\n\"\"\"Get the results of a run.\n\n    Args:\n        run_id: unique identifier for the run.\n        check_name: name of the check to get results for.\n        fpath: path to save the results to.\n    \"\"\"\n    url = f\"{self.base_url}/run/{run_id}/results\"\n    params: dict = {\"check_name\": check_name}\n    with self.client.stream(\"GET\", url, params=params) as response:\n        if not response.is_success:\n            logger.error(response.text)\n            response.raise_for_status()\n        else:\n            with open(fpath, \"wb\") as download_file:\n                for chunk in response.iter_bytes():\n                    download_file.write(chunk)\n</code></pre>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient.get_run","title":"<code>get_run(run_id)</code>","text":"<p>Get the status of a run.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>unique identifier for the run.</p> required <p>Returns:</p> Name Type Description <code>run</code> <p>information about the run along with a unique identifier.</p> Source code in <code>uptrain/framework/remote.py</code> <pre><code>def get_run(self, run_id: str):\n\"\"\"Get the status of a run.\n\n    Args:\n        run_id: unique identifier for the run.\n\n    Returns:\n        run: information about the run along with a unique identifier.\n    \"\"\"\n    url = f\"{self.base_url}/run/{run_id}\"\n    response = self.client.get(url)\n    return raise_or_return(response)\n</code></pre>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient.get_schedule","title":"<code>get_schedule(schedule_id)</code>","text":"<p>Get the status of a schedule.</p> <p>Parameters:</p> Name Type Description Default <code>schedule_id</code> <code>str</code> <p>unique identifier for the run.</p> required <p>Returns:</p> Name Type Description <code>run</code> <code>str</code> <p>information about the schedule along with a unique identifier.</p> Source code in <code>uptrain/framework/remote.py</code> <pre><code>def get_schedule(self, schedule_id: str) -&gt; str:\n\"\"\"Get the status of a schedule.\n\n    Args:\n        schedule_id: unique identifier for the run.\n\n    Returns:\n        run: information about the schedule along with a unique identifier.\n    \"\"\"\n    url = f\"{self.base_url}/schedule/{schedule_id}\"\n    response = self.client.get(url)\n    return raise_or_return(response)\n</code></pre>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient.list_runs","title":"<code>list_runs(num=10, only_completed=False)</code>","text":"<p>List all the runs on the server.</p> <ul> <li>filter by scheduled/completed/in-process?</li> </ul> Source code in <code>uptrain/framework/remote.py</code> <pre><code>def list_runs(self, num: int = 10, only_completed: bool = False):\n\"\"\"List all the runs on the server.\n\n    - filter by scheduled/completed/in-process?\n    \"\"\"\n    url = f\"{self.base_url}/runs\"\n    params: dict = {\"num\": num}\n    if only_completed:\n        params[\"status\"] = \"completed\"\n    response = self.client.get(url, params=params)\n    return raise_or_return(response)\n</code></pre>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient.list_schedules","title":"<code>list_schedules(num=10, active_only=True)</code>","text":"<p>List all the schedules on the server.</p> Source code in <code>uptrain/framework/remote.py</code> <pre><code>def list_schedules(self, num: int = 10, active_only: bool = True):\n\"\"\"List all the schedules on the server.\"\"\"\n    url = f\"{self.base_url}/schedules\"\n    params: dict = {\"num\": num, \"active_only\": active_only}\n    response = self.client.get(url, params=params)\n    return raise_or_return(response)\n</code></pre>"},{"location":"framework/Remote/#uptrain.framework.remote.APIClient.remove_schedule","title":"<code>remove_schedule(schedule_id)</code>","text":"<p>Remove a schedule.</p> <p>Parameters:</p> Name Type Description Default <code>schedule_id</code> <code>str</code> <p>unique identifier for the run.</p> required <p>Returns:</p> Name Type Description <code>run</code> <code>str</code> <p>information about the schedule along with a unique identifier.</p> Source code in <code>uptrain/framework/remote.py</code> <pre><code>def remove_schedule(self, schedule_id: str) -&gt; str:\n\"\"\"Remove a schedule.\n\n    Args:\n        schedule_id: unique identifier for the run.\n\n    Returns:\n        run: information about the schedule along with a unique identifier.\n    \"\"\"\n    url = f\"{self.base_url}/schedule/{schedule_id}\"\n    response = self.client.delete(url)\n    return raise_or_return(response)\n</code></pre>"},{"location":"framework/Signal/","title":"Signal","text":"<p>Signal Class wrapper for any dataframe column</p> <p>Attributes:</p> Name Type Description <code>col_name</code> <code>str</code> <p>Column Name</p> <code>identifier</code> <code>str</code> <p>Used as an identifier for printing </p> Methods <p>run(self, data): Evaluates on given data</p> Source code in <code>uptrain/framework/signal.py</code> <pre><code>class Signal:\n\"\"\"\n    Signal Class wrapper for any dataframe column\n\n    Attributes:\n        col_name (str): Column Name\n        identifier (str): Used as an identifier for printing \n\n    Methods:\n        run(self, data): Evaluates on given data\n\n    \"\"\"\n\n    def __init__(self, col_name=\"\"):\n        self.col_name = col_name\n        self.identifier = self.col_name\n        self.children = []\n\n    def __json__(self):\n        return {\"col_name\": str(self)}\n\n    def run(self, data: pl.DataFrame) -&gt; pl.Series:\n        return data[self.col_name].to_numpy()\n\n    def __invert__(self):\n        return InvertSignal(self)\n\n    def __add__(self, other):\n        return AddSignal(self, other)\n\n    def __mul__(self, other):\n        return MulSignal(self, other)\n\n    def __and__(self, other):\n        return AndSignal(self, other)\n\n    def __or__(self, other):\n        return OrSignal(self, other)\n\n    def __xor__(self, other):\n        return XorSignal(self, other)\n\n    def __gt__(self, other):\n        return GreaterThanSignal(self, other)\n\n    def __lt__(self, other):\n        return LessThanSignal(self, other)\n\n    def __eq__(self, other):\n        return EqualToSignal(self, other)\n\n    def __ge__(self, other):\n        return GreaterEqualToSignal(self, other)\n\n    def __le__(self, other):\n        return LessEqualToSignal(self, other)\n\n    def __ne__(self, other):\n        return NotEqualToSignal(self, other)\n\n    def __str__(self):\n        txt = str(self.identifier)\n        if len(self.children):\n            txt += \"(\"\n            txt += \",\".join([str(x) for x in self.children])\n            txt += \")\"\n        return txt\n</code></pre>"},{"location":"operators/Accuracy/","title":"Accuracy","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator for computing accuracy measures between predicted values and ground truth values.</p> <p>Attributes:</p> Name Type Description <code>kind</code> <code>Literal['NOT_EQUAL', 'ABS_ERROR']</code> <p>The type of accuracy measure.</p> <code>col_in_prediction</code> <code>str</code> <p>The name of the column containing the predicted values.</p> <code>col_in_ground_truth</code> <code>str</code> <p>The name of the column containing the ground truth values.</p> <code>col_out</code> <code>str</code> <p>The name of the output column containing the accuracy scores.</p> Example <pre><code>from uptrain.operators import Accuracy\nfrom uptrain.operators import CsvReader\n\n# Create an instance of the Accuracy operator\nop = Accuracy(\n        kind=\"NOT_EQUAL\",\n        col_in_prediction=\"prediction\",\n        col_in_ground_truth=\"ground_truth\"\n    )\n\n# Set up the operator\nop.setup()\n\n# Run the operator on the input data\ninput_data = pl.DataFrame(...)\naccuracy_scores = op.run(input_data)[\"output\"]\n\n# Print the accuracy scores\nprint(accuracy_scores)\n</code></pre> Output <pre><code>shape: (3,)\nSeries: '_col_0' [bool]\n[\n        true\n        false\n        true\n]\n</code></pre> Source code in <code>uptrain/operators/metrics.py</code> <pre><code>@register_op\nclass Accuracy(ColumnOp):\n\"\"\"\n    Operator for computing accuracy measures between predicted values and ground truth values.\n\n    Attributes:\n        kind (Literal[\"NOT_EQUAL\", \"ABS_ERROR\"]): The type of accuracy measure.\n        col_in_prediction (str): The name of the column containing the predicted values.\n        col_in_ground_truth (str): The name of the column containing the ground truth values.\n        col_out (str): The name of the output column containing the accuracy scores.\n\n    Example:\n        ```\n        from uptrain.operators import Accuracy\n        from uptrain.operators import CsvReader\n\n        # Create an instance of the Accuracy operator\n        op = Accuracy(\n                kind=\"NOT_EQUAL\",\n                col_in_prediction=\"prediction\",\n                col_in_ground_truth=\"ground_truth\"\n            )\n\n        # Set up the operator\n        op.setup()\n\n        # Run the operator on the input data\n        input_data = pl.DataFrame(...)\n        accuracy_scores = op.run(input_data)[\"output\"]\n\n        # Print the accuracy scores\n        print(accuracy_scores)\n        ```\n\n    Output:\n        ```\n        shape: (3,)\n        Series: '_col_0' [bool]\n        [\n                true\n                false\n                true\n        ]\n        ```\n\n    \"\"\"\n\n    kind: t.Literal[\"NOT_EQUAL\", \"ABS_ERROR\"]\n    col_in_prediction: str = \"prediction\"\n    col_in_ground_truth: str = \"ground_truth\"\n    col_out: str = \"accuracy\"\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        preds = np.array(data.get_column(self.col_in_prediction))\n        gts = np.array(data.get_column(self.col_in_ground_truth))\n\n        if self.kind == \"NOT_EQUAL\":\n            acc = np.not_equal(preds, gts)\n        else:\n            acc = np.abs(preds - gts)\n        return {\"output\": data.with_columns([pl.Series(self.col_out, acc)])}\n</code></pre>"},{"location":"operators/ColumnExpand/","title":"ColumnExpand","text":"<p>             Bases: <code>TransformOp</code></p> <p>Table operation to return the input DataFrame as it is without any modifications.</p> <p>Attributes:</p> Name Type Description <code>col_out_names</code> <code>list[str]</code> <p>The names of the output columns. Must be the same length as <code>col_vals</code>.</p> <code>col_vals</code> <code>list[Any]</code> <p>The values for the output columns. Must be the same length as <code>col_out_names</code>.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the input DataFrame.</p> Example <pre><code>from uptrain.operators import ColumnExpand\ndf = pl.DataFrame({\n    \"column1\": [1, 2, 3],\n    \"column2\": [\"A\", \"B\", \"C\"]\n})\n\n# Create an instance of the ColumnExpand class\nexpand_op = ColumnExpand(\n                col_out_names=[\"column1\", \"column2\"],\n                col_vals=[df[\"column1\"], df[\"column2\"]]\n            )\n\n# Run the expand operation\noutput_df = expand_op.run(df)[\"output\"]\n\n# Print the output DataFrame\nprint(output_df)\n</code></pre> Output <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 column1 \u2506 column2 \u2502\n\u2502 ---     \u2506 ---     \u2502\n\u2502 i64     \u2506 str     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1       \u2506 A       \u2502\n\u2502 2       \u2506 B       \u2502\n\u2502 3       \u2506 C       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>uptrain/operators/table.py</code> <pre><code>@register_op\nclass ColumnExpand(TransformOp):\n\"\"\"\n    Table operation to return the input DataFrame as it is without any modifications.\n\n    Attributes:\n        col_out_names (list[str]): The names of the output columns. Must be the same length as `col_vals`.\n        col_vals (list[Any]): The values for the output columns. Must be the same length as `col_out_names`.\n\n    Returns:\n        dict: A dictionary containing the input DataFrame.\n\n    Example:\n        ```\n        from uptrain.operators import ColumnExpand\n        df = pl.DataFrame({\n            \"column1\": [1, 2, 3],\n            \"column2\": [\"A\", \"B\", \"C\"]\n        })\n\n        # Create an instance of the ColumnExpand class\n        expand_op = ColumnExpand(\n                        col_out_names=[\"column1\", \"column2\"],\n                        col_vals=[df[\"column1\"], df[\"column2\"]]\n                    )\n\n        # Run the expand operation\n        output_df = expand_op.run(df)[\"output\"]\n\n        # Print the output DataFrame\n        print(output_df)\n        ```\n\n    Output:\n        ```\n        shape: (3, 2)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 column1 \u2506 column2 \u2502\n        \u2502 ---     \u2506 ---     \u2502\n        \u2502 i64     \u2506 str     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 1       \u2506 A       \u2502\n        \u2502 2       \u2506 B       \u2502\n        \u2502 3       \u2506 C       \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n    \"\"\"\n\n    col_out_names: list[str]\n    col_vals: list[t.Any]\n\n    def setup(self, settings: Settings):\n        assert len(self.col_out_names) == len(self.col_vals)\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        out = data.with_columns(\n            [\n                pl.lit(self.col_vals[idx]).alias(self.col_out_names[idx])\n                for idx in range(len(self.col_out_names))\n            ]\n        )\n        return {\"output\": out}\n</code></pre>"},{"location":"operators/ConceptDrift/","title":"ConceptDrift","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator for detecting concept drift using the DDM (Drift Detection Method) or ADWIN (Adaptive Windowing) algorithm.</p> <p>Attributes:</p> Name Type Description <code>algorithm</code> <code>Literal['DDM', 'ADWIN']</code> <p>The algorithm to use for concept drift detection.</p> <code>params</code> <code>Union[ParamsDDM, ParamsADWIN]</code> <p>The parameters for the selected algorithm.</p> <code>col_in_measure</code> <code>str</code> <p>The name of the column in the input data representing the metric to measure concept drift.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the specified algorithm does not match the type of the parameters.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import ParamsDDM, ConceptDrift\n\n# Create an instance of the ParamsDDM class with the parameters\n\nparams_ddm = ParamsDDM(\n                warm_start=500,\n                warn_threshold=2.0,\n                alarm_threshold=3.0\n            )\n\n# Create an instance of the ConceptDrift operator\nop = ConceptDrift(\n        algorithm=\"DDM\",\n        params=params_ddm,\n        col_in_measure=\"metric\"\n    )\n\n# Set up the operator\nop.setup()\n\n# Run the operator on the input data\ninput_data = pl.DataFrame(...)\noutput = op.run(input_data)[\"extra\"]\n\n# Check the detected concept drift information\nif output[\"alert_info\"] is not None:\n    print(\"Counter:\", output[\"alert_info\"][\"counter\"])\n</code></pre> Output <pre><code>INFO     | uptrain.operators.drift:run:181 - Drift detected using DDM!\nCounter: 129466\n</code></pre> Source code in <code>uptrain/operators/drift.py</code> <pre><code>@register_op\nclass ConceptDrift(ColumnOp):\n\"\"\"\n    Operator for detecting concept drift using the DDM (Drift Detection Method) or ADWIN (Adaptive Windowing) algorithm.\n\n    Attributes:\n        algorithm (Literal[\"DDM\", \"ADWIN\"]): The algorithm to use for concept drift detection.\n        params (Union[ParamsDDM, ParamsADWIN]): The parameters for the selected algorithm.\n        col_in_measure (str): The name of the column in the input data representing the metric to measure concept drift.\n\n    Raises:\n        ValueError: If the specified algorithm does not match the type of the parameters.\n\n    Example:\n        ```py\n        import polars as pl\n        from uptrain.operators import ParamsDDM, ConceptDrift\n\n        # Create an instance of the ParamsDDM class with the parameters\n\n        params_ddm = ParamsDDM(\n                        warm_start=500,\n                        warn_threshold=2.0,\n                        alarm_threshold=3.0\n                    )\n\n        # Create an instance of the ConceptDrift operator\n        op = ConceptDrift(\n                algorithm=\"DDM\",\n                params=params_ddm,\n                col_in_measure=\"metric\"\n            )\n\n        # Set up the operator\n        op.setup()\n\n        # Run the operator on the input data\n        input_data = pl.DataFrame(...)\n        output = op.run(input_data)[\"extra\"]\n\n        # Check the detected concept drift information\n        if output[\"alert_info\"] is not None:\n            print(\"Counter:\", output[\"alert_info\"][\"counter\"])\n        ```\n\n    Output:\n        ```\n        INFO     | uptrain.operators.drift:run:181 - Drift detected using DDM!\n        Counter: 129466\n        ```\n    \"\"\"\n\n    algorithm: t.Literal[\"DDM\", \"ADWIN\"]\n    params: t.Union[ParamsDDM, ParamsADWIN]\n    col_in_measure: str = \"metric\"\n\n    @root_validator\n    def _check_params(cls, values):\n\"\"\"\n        Check if the parameters are valid for the specified algorithm.\n\n        \"\"\"\n        algo = values[\"algorithm\"]\n        params = values[\"params\"]\n        if algo == \"DDM\" and not isinstance(params, ParamsDDM):\n            raise ValueError(\n                f\"Expected params to be of type {ParamsDDM} for algorithm - DDM\"\n            )\n        elif algo == \"ADWIN\" and not isinstance(params, ParamsADWIN):\n            raise ValueError(\n                f\"Expected params to be of type {ParamsADWIN} for algorithm - ADWIN\"\n            )\n        return values\n\n    def setup(self, settings: Settings):\n        if self.algorithm == \"DDM\":\n            self._algo_obj = drift.binary.DDM(**self.params.dict())  # type: ignore\n        elif self.algorithm == \"ADWIN\":\n            self._algo_obj = drift.ADWIN(**self.params.dict())  # type: ignore\n        self._counter = 0\n        self._avg_accuracy = 0.0\n        self._cuml_accuracy = 0.0\n        self._alert_info = None\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        ser = data.get_column(self.col_in_measure)\n\n        for val in ser:\n            self._algo_obj.update(val)\n            if self._algo_obj.drift_detected and self._alert_info is None:\n                msg = f\"Drift detected using {self.algorithm}!\"\n                self._alert_info = {\"counter\": self._counter, \"msg\": msg}\n                logger.info(msg)\n\n            self._counter += 1\n            self._cuml_accuracy += val\n\n        self._avg_accuracy = (\n            self._cuml_accuracy / self._counter if self._counter &gt; 0 else 0.0\n        )\n        return {\n            \"output\": None,\n            \"extra\": {\n                \"counter\": self._counter,\n                \"avg_accuracy\": self._avg_accuracy,\n                \"alert_info\": self._alert_info,\n            },\n        }\n</code></pre>"},{"location":"operators/CosineSimilarity/","title":"CosineSimilarity","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Column operation to calculate the cosine similarity between two vectors representing text.</p> <p>Attributes:</p> Name Type Description <code>col_in_vector_1</code> <code>str</code> <p>The name of the column containing the first vector.</p> <code>col_in_vector_2</code> <code>str</code> <p>The name of the column containing the second vector.</p> <code>col_out</code> <code>str</code> <p>The name of the output column containing the cosine similarity scores.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the cosine similarity scores.</p> Example <pre><code>import polars as pl\nimport numpy as np\nfrom uptrain.operators import CosineSimilarity\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"vector_1\": [np.array([0.1, 0.2, 0.3]), np.array([0.4, 0.5, 0.6])],\n    \"vector_2\": [np.array([0.7, 0.8, 0.9]), np.array([0.2, 0.3, 0.4])]\n})\n\n# Create an instance of the CosineSimilarity class\nsimilarity_op = CosineSimilarity(col_in_vector_1=\"vector_1\", col_in_vector_2=\"vector_2\")\n\n# Calculate the cosine similarity between the two vectors\nresult = similarity_op.run(df)\nsimilarity_scores = result[\"output\"]\n\n# Print the similarity scores\nprint(similarity_scores)\n</code></pre> Output <pre><code>shape: (2,)\nSeries: '_col_0' [f64]\n[\n        1.861259\n        0.288437\n]\n</code></pre> Source code in <code>uptrain/operators/similarity.py</code> <pre><code>@register_op\nclass CosineSimilarity(ColumnOp):\n\"\"\"\n    Column operation to calculate the cosine similarity between two vectors representing text.\n\n    Attributes:\n        col_in_vector_1 (str): The name of the column containing the first vector.\n        col_in_vector_2 (str): The name of the column containing the second vector.\n        col_out (str): The name of the output column containing the cosine similarity scores.\n\n    Returns:\n        dict: A dictionary containing the cosine similarity scores.\n\n    Example:\n        ```\n        import polars as pl\n        import numpy as np\n        from uptrain.operators import CosineSimilarity\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"vector_1\": [np.array([0.1, 0.2, 0.3]), np.array([0.4, 0.5, 0.6])],\n            \"vector_2\": [np.array([0.7, 0.8, 0.9]), np.array([0.2, 0.3, 0.4])]\n        })\n\n        # Create an instance of the CosineSimilarity class\n        similarity_op = CosineSimilarity(col_in_vector_1=\"vector_1\", col_in_vector_2=\"vector_2\")\n\n        # Calculate the cosine similarity between the two vectors\n        result = similarity_op.run(df)\n        similarity_scores = result[\"output\"]\n\n        # Print the similarity scores\n        print(similarity_scores)\n        ```\n\n    Output:\n        ```\n        shape: (2,)\n        Series: '_col_0' [f64]\n        [\n                1.861259\n                0.288437\n        ]\n        ```\n\n    \"\"\"\n\n    col_in_vector_1: str\n    col_in_vector_2: str\n    col_out: str = \"cosine_similarity\"\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        vector_1 = data.get_column(self.col_in_vector_1)\n        vector_2 = data.get_column(self.col_in_vector_2)\n\n        results = []\n        for i in range(len(vector_1)):\n            v1 = np.array(vector_1[i])\n            v2 = np.array(vector_2[i])\n            similarity_score = np.dot(v1, v2) / np.linalg.norm(v1) * np.linalg.norm(v2)\n            results.append(similarity_score)\n\n        return {\"output\": data.with_columns(pl.Series(results).alias(self.col_out))}\n</code></pre>"},{"location":"operators/Distribution/","title":"Distribution","text":"<p>             Bases: <code>TransformOp</code></p> <p>Operator for computing distribution of similarity metrics.</p> <p>Attributes:</p> Name Type Description <code>kind</code> <code>Literal['cosine_similarity', 'rouge']</code> <p>The type of similarity metric.</p> <code>col_in_embs</code> <code>list[str]</code> <p>The input columns containing embeddings.</p> <code>col_in_groupby</code> <code>list[str]</code> <p>The columns to group by.</p> <code>col_out</code> <code>list[str] | None</code> <p>The output columns. If None, automatically generated column names will be used.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the number of output columns does not match the number of input embedding columns.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import Distribution\n\n# Create an instance of the Distribution operator\nop = Distribution(\n        kind=\"cosine_similarity\",\n        col_in_embs=[\"context_embeddings\", \"response_embeddings\"],\n        col_in_groupby=[\"question_idx\", \"experiment_id\"],\n        col_out=[\"similarity-context\", \"similarity-response\"],\n    )\n\n# Set up the operator\nop.setup()\n\n# Run the operator on the input data\ninput_data = pl.DataFrame(...)\noutput = op.run(input_data)[\"output\"]\n\n# Print the output\nprint(output)\n</code></pre> Output <pre><code>shape: (90, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 question_idx \u2506 experiment_id \u2506 similarity-context \u2506 similarity-response \u2502\n\u2502 ---          \u2506 ---           \u2506 ---                \u2506 ---                 \u2502\n\u2502 i64          \u2506 i64           \u2506 f64                \u2506 f64                 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2            \u2506 0             \u2506 0.314787           \u2506 1.0                 \u2502\n\u2502 2            \u2506 0             \u2506 0.387398           \u2506 0.204949            \u2502\n\u2502 2            \u2506 0             \u2506 0.344797           \u2506 0.23195             \u2502\n\u2502 2            \u2506 0             \u2506 0.306041           \u2506 1.0                 \u2502\n\u2502 \u2026            \u2506 \u2026             \u2506 \u2026                  \u2506 \u2026                   \u2502\n\u2502 0            \u2506 2             \u2506 0.997804           \u2506 0.996358            \u2502\n\u2502 0            \u2506 2             \u2506 0.66862            \u2506 0.300155            \u2502\n\u2502 0            \u2506 2             \u2506 0.224229           \u2506 0.637781            \u2502\n\u2502 0            \u2506 2             \u2506 0.379936           \u2506 0.260659            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>uptrain/operators/embs.py</code> <pre><code>@register_op\nclass Distribution(TransformOp):\n\"\"\"\n    Operator for computing distribution of similarity metrics.\n\n    Attributes:\n        kind (Literal[\"cosine_similarity\", \"rouge\"]): The type of similarity metric.\n        col_in_embs (list[str]): The input columns containing embeddings.\n        col_in_groupby (list[str]): The columns to group by.\n        col_out (list[str] | None): The output columns. If None, automatically generated column names will be used.\n\n    Raises:\n        AssertionError: If the number of output columns does not match the number of input embedding columns.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import Distribution\n\n        # Create an instance of the Distribution operator\n        op = Distribution(\n                kind=\"cosine_similarity\",\n                col_in_embs=[\"context_embeddings\", \"response_embeddings\"],\n                col_in_groupby=[\"question_idx\", \"experiment_id\"],\n                col_out=[\"similarity-context\", \"similarity-response\"],\n            )\n\n        # Set up the operator\n        op.setup()\n\n        # Run the operator on the input data\n        input_data = pl.DataFrame(...)\n        output = op.run(input_data)[\"output\"]\n\n        # Print the output\n        print(output)\n        ```\n\n\n    Output:\n        ```\n        shape: (90, 4)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 question_idx \u2506 experiment_id \u2506 similarity-context \u2506 similarity-response \u2502\n        \u2502 ---          \u2506 ---           \u2506 ---                \u2506 ---                 \u2502\n        \u2502 i64          \u2506 i64           \u2506 f64                \u2506 f64                 \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 2            \u2506 0             \u2506 0.314787           \u2506 1.0                 \u2502\n        \u2502 2            \u2506 0             \u2506 0.387398           \u2506 0.204949            \u2502\n        \u2502 2            \u2506 0             \u2506 0.344797           \u2506 0.23195             \u2502\n        \u2502 2            \u2506 0             \u2506 0.306041           \u2506 1.0                 \u2502\n        \u2502 \u2026            \u2506 \u2026             \u2506 \u2026                  \u2506 \u2026                   \u2502\n        \u2502 0            \u2506 2             \u2506 0.997804           \u2506 0.996358            \u2502\n        \u2502 0            \u2506 2             \u2506 0.66862            \u2506 0.300155            \u2502\n        \u2502 0            \u2506 2             \u2506 0.224229           \u2506 0.637781            \u2502\n        \u2502 0            \u2506 2             \u2506 0.379936           \u2506 0.260659            \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n    \"\"\"\n\n    kind: t.Literal[\"cosine_similarity\", \"rouge\"]\n    col_in_embs: list[str]\n    col_in_groupby: list[str]\n    col_out: list[str] | None = None\n\n    @root_validator(pre=True)\n    def _check_cols(cls, values):\n\"\"\"\n        Validator to check the validity of input and output column lists.\n\n        Args:\n            values (dict): The input attribute values.\n\n        Returns:\n            dict: The validated attribute values.\n\n        Raises:\n            AssertionError: If the number of output columns does not match the number of input embedding columns.\n\n        \"\"\"\n        if values[\"col_out\"] is not None:\n            assert len(values[\"col_out\"]) == len(\n                values[\"col_in_embs\"]\n            ), \"Distribution Op needs as many output columns as input embedding columns\"\n        return values\n\n    def setup(self, settings: Settings):\n        if self.kind == \"cosine_similarity\":\n            self._agg_func = get_cosine_sim_dist\n        elif self.kind == \"rouge\":\n            self._agg_func = get_rouge_score\n        else:\n            raise NotImplementedError(\n                f\"Similarity metric: {self.kind} not supported for now.\"\n            )\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        if self.col_out is None:\n            agg_cols = [get_output_col_name_at(i) for i in range(len(self.col_in_embs))]\n        else:\n            agg_cols = self.col_out\n\n        dist_df = (\n            data.groupby(self.col_in_groupby, maintain_order=True)\n            .agg(\n                [\n                    pl.col(_col_in).apply(self._agg_func).alias(_col_out)\n                    for _col_in, _col_out in zip(self.col_in_embs, agg_cols)\n                ]\n            )\n            .explode(agg_cols)\n        )\n        return {\"output\": dist_df}\n</code></pre>"},{"location":"operators/UMAP/","title":"UMAP","text":"<p>             Bases: <code>TransformOp</code></p> <p>Operator for performing UMAP dimensionality reduction.</p> <p>Attributes:</p> Name Type Description <code>col_in_embs_1</code> <code>str</code> <p>The first input column containing embeddings.</p> <code>col_in_embs_2</code> <code>str</code> <p>The second input column containing embeddings.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import UMAP\n\n# Create an instance of the UMAP operator\nop = UMAP(\n        col_in_embs_1=\"embeddings\",\n        col_in_embs_2=\"embeddings_2\"\n    )\n\n# Set up the operator\nop.setup()\n\n# Run the operator on the input data\ninput_data = pl.DataFrame(...)\noutput = op.run(input_data)\n\n# Get the output DataFrame\numap_df = output[\"output\"]\n</code></pre> Output <pre><code>shape: (180, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 umap_0    \u2506 umap_1    \u2506 symbol \u2506 cluster \u2502\n\u2502 ---       \u2506 ---       \u2506 ---    \u2506 ---     \u2502\n\u2502 f32       \u2506 f32       \u2506 str    \u2506 str     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 14.922973 \u2506 4.189351  \u2506 star   \u2506 default \u2502\n\u2502 40.150131 \u2506 8.316374  \u2506 star   \u2506 default \u2502\n\u2502 39.838726 \u2506 8.043911  \u2506 star   \u2506 default \u2502\n\u2502 40.064186 \u2506 8.510321  \u2506 star   \u2506 default \u2502\n\u2502 \u2026         \u2506 \u2026         \u2506 \u2026      \u2506 \u2026       \u2502\n\u2502 12.529058 \u2506 -0.074642 \u2506 circle \u2506 default \u2502\n\u2502 3.296701  \u2506 21.817385 \u2506 circle \u2506 default \u2502\n\u2502 16.352724 \u2506 12.401769 \u2506 circle \u2506 default \u2502\n\u2502 3.858282  \u2506 5.807839  \u2506 circle \u2506 default \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>uptrain/operators/embs.py</code> <pre><code>@register_op\nclass UMAP(TransformOp):\n\"\"\"\n    Operator for performing UMAP dimensionality reduction.\n\n    Attributes:\n        col_in_embs_1 (str): The first input column containing embeddings.\n        col_in_embs_2 (str): The second input column containing embeddings.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import UMAP\n\n        # Create an instance of the UMAP operator\n        op = UMAP(\n                col_in_embs_1=\"embeddings\",\n                col_in_embs_2=\"embeddings_2\"\n            )\n\n        # Set up the operator\n        op.setup()\n\n        # Run the operator on the input data\n        input_data = pl.DataFrame(...)\n        output = op.run(input_data)\n\n        # Get the output DataFrame\n        umap_df = output[\"output\"]\n        ```\n\n    Output:\n        ```\n        shape: (180, 4)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 umap_0    \u2506 umap_1    \u2506 symbol \u2506 cluster \u2502\n        \u2502 ---       \u2506 ---       \u2506 ---    \u2506 ---     \u2502\n        \u2502 f32       \u2506 f32       \u2506 str    \u2506 str     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 14.922973 \u2506 4.189351  \u2506 star   \u2506 default \u2502\n        \u2502 40.150131 \u2506 8.316374  \u2506 star   \u2506 default \u2502\n        \u2502 39.838726 \u2506 8.043911  \u2506 star   \u2506 default \u2502\n        \u2502 40.064186 \u2506 8.510321  \u2506 star   \u2506 default \u2502\n        \u2502 \u2026         \u2506 \u2026         \u2506 \u2026      \u2506 \u2026       \u2502\n        \u2502 12.529058 \u2506 -0.074642 \u2506 circle \u2506 default \u2502\n        \u2502 3.296701  \u2506 21.817385 \u2506 circle \u2506 default \u2502\n        \u2502 16.352724 \u2506 12.401769 \u2506 circle \u2506 default \u2502\n        \u2502 3.858282  \u2506 5.807839  \u2506 circle \u2506 default \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        ```\n\n    \"\"\"\n\n    col_in_embs_1: str\n    col_in_embs_2: str\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        embs_1 = np.asarray(data[self.col_in_embs_1].to_list())\n        embs_2 = np.asarray(data[self.col_in_embs_2].to_list())\n\n        embs_list = list(embs_1)\n        embs_list.extend(list(embs_2))\n        combined_embs = np.array(embs_list)\n        symbols = [\"star\"] * len(embs_1) + [\"circle\"] * len(embs_2)\n        clusters = [\"default\"] * len(combined_embs)\n        umap_output = umap.UMAP().fit_transform(combined_embs)  # type: ignore\n        return {\n            \"output\": pl.DataFrame(\n                [\n                    pl.Series(values=umap_output[:, 0]).alias(\"umap_0\"),\n                    pl.Series(values=umap_output[:, 1]).alias(\"umap_1\"),\n                    pl.Series(values=symbols).alias(\"symbol\"),\n                    pl.Series(values=clusters).alias(\"cluster\"),\n                ]\n            )\n        }\n</code></pre>"},{"location":"operators/IO/BigQueryReader/","title":"BigQueryReader","text":"<p>             Bases: <code>TransformOp</code></p> <p>Read data from a bigquery table.</p> <p>NOTE: To use this operator, you must include the GCP service account credentials in the settings, using the key <code>gcp_service_account_credentials</code>.</p> <p>Attributes:</p> Name Type Description <code>query</code> <code>str</code> <p>Query to run against the BigQuery table.</p> <code>col_timestamp</code> <code>str</code> <p>Column name to use as the timestamp column. Only used in the context of monitoring.</p> Example <pre><code>from uptrain.operators.io import BigQueryReader\n\nquery = \"SELECT * FROM `bigquery-public-data.samples.shakespeare` LIMIT 10\"\nreader = BigQueryReader(\n    query=query,\n    col_timestamp=\"timestamp\"\n)\noutput = reader.setup().run()[\"output\"]\n</code></pre> Source code in <code>uptrain/operators/io/bq.py</code> <pre><code>@register_op\nclass BigQueryReader(TransformOp):\n\"\"\"Read data from a bigquery table.\n\n    NOTE: To use this operator, you must include the GCP service account credentials in\n    the settings, using the key `gcp_service_account_credentials`.\n\n    Attributes:\n        query (str): Query to run against the BigQuery table.\n        col_timestamp (str): Column name to use as the timestamp column. Only used in the context of monitoring.\n\n    Example:\n        ```python\n        from uptrain.operators.io import BigQueryReader\n\n        query = \"SELECT * FROM `bigquery-public-data.samples.shakespeare` LIMIT 10\"\n        reader = BigQueryReader(\n            query=query,\n            col_timestamp=\"timestamp\"\n        )\n        output = reader.setup().run()[\"output\"]\n        ```\n    \"\"\"\n\n    query: str\n    col_timestamp: str = \"timestamp\"\n\n    def setup(self, settings: Settings):\n        from google.oauth2 import service_account\n\n        gcp_sa_creds = settings.check_and_get(\"gcp_service_account_credentials\")\n        credentials = service_account.Credentials.from_service_account_info(\n            gcp_sa_creds\n        )\n        self._client = bigquery.Client(credentials=credentials)\n        return self\n\n    def run(self) -&gt; TYPE_TABLE_OUTPUT:\n        query_job = self._client.query(self.query)\n        rows = query_job.result()\n        return {\"output\": pl.from_arrow(rows.to_arrow())}\n</code></pre>"},{"location":"operators/IO/CsvReader/","title":"CsvReader","text":"<p>             Bases: <code>TransformOp</code></p> <p>Reads data from a csv file.</p> <p>Attributes:</p> Name Type Description <code>fpath</code> <code>str</code> <p>Path to the csv file.</p> <code>batch_size</code> <code>Optional[int]</code> <p>Number of rows to read at a time. Defaults to None, which reads the entire file.</p> Source code in <code>uptrain/operators/io/base.py</code> <pre><code>@register_op\nclass CsvReader(TransformOp):\n\"\"\"Reads data from a csv file.\n\n    Attributes:\n        fpath (str): Path to the csv file.\n        batch_size (Optional[int]): Number of rows to read at a time. Defaults to None, which reads the entire file.\n\n    \"\"\"\n\n    fpath: str\n    batch_size: t.Optional[int] = None\n\n    def setup(self, settings: Settings):\n        self._executor = TextReaderExecutor(self)\n        return self\n\n    def run(self) -&gt; TYPE_TABLE_OUTPUT:\n        return {\"output\": self._executor.run()}\n</code></pre>"},{"location":"operators/IO/DeltaReader/","title":"DeltaReader","text":"<p>             Bases: <code>TransformOp</code></p> <p>Reads data from a Delta Lake table.</p> <p>Attributes:</p> Name Type Description <code>fpath</code> <code>str</code> <p>File path to the Delta Lake table.</p> <code>batch_split</code> <code>bool</code> <p>Whether to read the table in batches. Defaults to False.</p> Source code in <code>uptrain/operators/io/base.py</code> <pre><code>@register_op\nclass DeltaReader(TransformOp):\n\"\"\"Reads data from a Delta Lake table.\n\n    Attributes:\n        fpath (str): File path to the Delta Lake table.\n        batch_split (bool): Whether to read the table in batches. Defaults to False.\n\n    \"\"\"\n\n    fpath: str\n    batch_split: bool = False\n    _dataset: t.Any  # pyarrow dataset\n    _batch_generator: t.Optional[t.Iterator[t.Any]]  # record batch generator\n\n    def setup(self, settings: Settings):\n        self._dataset = dl.DeltaTable(self.fpath).to_pyarrow_dataset()\n        if self.is_incremental:\n            self._batch_generator = iter(self._dataset.to_batches())\n        return self\n\n    @property\n    def is_incremental(self) -&gt; bool:\n        return self.batch_split is True\n\n    def run(self) -&gt; TYPE_TABLE_OUTPUT:\n        if not self.is_incremental:\n            data = pl.from_arrow(self._dataset.to_table())\n        else:\n            try:\n                data = pl.from_arrow(next(self._batch_generator))  # type: ignore\n            except StopIteration:\n                data = None\n\n        if data is not None:\n            assert isinstance(data, pl.DataFrame)\n        return {\"output\": data}\n</code></pre>"},{"location":"operators/IO/DeltaWriter/","title":"DeltaWriter","text":"<p>             Bases: <code>OpBaseModel</code></p> Source code in <code>uptrain/operators/io/base.py</code> <pre><code>@register_op\nclass DeltaWriter(OpBaseModel):\n    fpath: str\n    columns: t.Optional[list[str]] = None\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        if self.columns is None:\n            self.columns = list(data.columns)\n        assert set(self.columns) == set(data.columns)\n        data.write_delta(self.fpath, mode=\"append\")\n        return {\"output\": None}\n\n    def to_reader(self):\n        return DeltaReader(fpath=self.fpath)  # type: ignore\n</code></pre>"},{"location":"operators/IO/DuckDBReader/","title":"DuckDBReader","text":"<p>             Bases: <code>TransformOp</code></p> <p>Read data from a Duckdb table.</p> <p>Attributes:</p> Name Type Description <code>fpath</code> <code>str</code> <p>Path to the Duckdb file.</p> <code>query</code> <code>str</code> <p>Query to run against the duckdb database.</p> <code>col_timestamp</code> <code>str</code> <p>Column name to use as the timestamp column. Only used in the context of monitoring.</p> Example <pre><code>from uptrain.operators.io import DuckDBReader\n\nreader = DuckDBReader(\n    fpath=\"data/duckdb.db\",\n    query=\"SELECT * FROM my_table\",\n    col_timestamp=\"timestamp\",\n)\noutput = reader.setup().run()[\"output\"]\n</code></pre> Source code in <code>uptrain/operators/io/duck.py</code> <pre><code>@register_op\nclass DuckDBReader(TransformOp):\n\"\"\"Read data from a Duckdb table.\n\n    Attributes:\n        fpath (str): Path to the Duckdb file.\n        query (str): Query to run against the duckdb database.\n        col_timestamp (str): Column name to use as the timestamp column. Only used in the context of monitoring.\n\n    Example:\n        ```python\n        from uptrain.operators.io import DuckDBReader\n\n        reader = DuckDBReader(\n            fpath=\"data/duckdb.db\",\n            query=\"SELECT * FROM my_table\",\n            col_timestamp=\"timestamp\",\n        )\n        output = reader.setup().run()[\"output\"]\n        ```\n    \"\"\"\n\n    fpath: str\n    query: str\n    col_timestamp: str = \"timestamp\"\n\n    def setup(self, settings: Settings):\n        self._conn = duckdb.connect(self.fpath)\n        return self\n\n    def run(self) -&gt; TYPE_TABLE_OUTPUT:\n        res = self._conn.query(self.query).to_arrow_table()\n        return {\"output\": pl.from_arrow(res)}\n</code></pre>"},{"location":"operators/IO/ExcelReader/","title":"ExcelReader","text":"<p>             Bases: <code>TransformOp</code></p> <p>Reads an excel file.</p> <p>Attributes:</p> Name Type Description <code>fpath</code> <code>str</code> <p>Path to the xlsx file.</p> <code>batch_size</code> <code>Optional[int]</code> <p>Number of rows to read at a time. Defaults to None, which reads the entire file.</p> Source code in <code>uptrain/operators/io/excel.py</code> <pre><code>@register_op\nclass ExcelReader(TransformOp):\n\"\"\"Reads an excel file.\n\n    Attributes:\n        fpath (str): Path to the xlsx file.\n        batch_size (Optional[int]): Number of rows to read at a time. Defaults to None, which reads the entire file.\n\n    \"\"\"\n\n    fpath: str\n    batch_size: t.Optional[int] = None\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self) -&gt; TYPE_TABLE_OUTPUT:\n        return {\"output\": pl.read_excel(self.fpath)}\n</code></pre>"},{"location":"operators/IO/JsonReader/","title":"JsonReader","text":"<p>             Bases: <code>TransformOp</code></p> <p>Reads data from a json file.</p> <p>Attributes:</p> Name Type Description <code>fpath</code> <code>str</code> <p>Path to the json file.</p> <code>batch_size</code> <code>Optional[int]</code> <p>Number of rows to read at a time. Defaults to None, which reads the entire file.</p> Source code in <code>uptrain/operators/io/base.py</code> <pre><code>@register_op\nclass JsonReader(TransformOp):\n\"\"\"Reads data from a json file.\n\n    Attributes:\n        fpath (str): Path to the json file.\n        batch_size (Optional[int]): Number of rows to read at a time. Defaults to None, which reads the entire file.\n\n    \"\"\"\n\n    fpath: str\n    batch_size: t.Optional[int] = None\n\n    def setup(self, settings: Settings):\n        self._executor = TextReaderExecutor(self)\n        return self\n\n    def run(self) -&gt; TYPE_TABLE_OUTPUT:\n        return {\"output\": self._executor.run()}\n</code></pre>"},{"location":"operators/IO/JsonWriter/","title":"JsonWriter","text":"<p>             Bases: <code>OpBaseModel</code></p> Source code in <code>uptrain/operators/io/base.py</code> <pre><code>@register_op\nclass JsonWriter(OpBaseModel):\n    fpath: str\n    columns: t.Optional[list[str]] = None\n\n    def setup(self, settings: Settings):\n        return self\n\n    def to_reader(self):\n        return JsonReader(fpath=self.fpath)  # type: ignore\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        if self.columns is None:\n            self.columns = list(data.columns)\n        assert set(self.columns) == set(data.columns)\n        with open(self.fpath, \"a\") as f:\n            f.write(data.write_ndjson())\n        return {\"output\": None}\n</code></pre>"},{"location":"operators/charts/BarChart/","title":"BarChart","text":"<p>             Bases: <code>Chart</code></p> <p>Operator to generate a bar chart.</p> <p>Attributes:</p> Name Type Description <code>props</code> <code>dict</code> <p>Additional properties to pass to the BarChart constructor.</p> <code>x</code> <code>str</code> <p>The name of the column to use for the x-axis.</p> <code>y</code> <code>str</code> <p>The name of the column to use for the y-axis.</p> <code>color</code> <code>str</code> <p>The name of the column to use for the color.</p> <code>barmode</code> <code>str</code> <p>The type of bar chart to generate.</p> <code>title</code> <code>str</code> <p>The title of the chart.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the chart object.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import BarChart\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"x\": [1, 2, 3, 4, 5],\n    \"y\": [10, 20, 15, 25, 30]\n})\n\n# Create a bar chart using the BarChart class\nbar_chart = BarChart(x=\"x\", y=\"y\", title=\"Bar Chart\")\n\n# Generate the bar chart\nchart = bar_chart.run(df)[\"extra\"][\"chart\"]\n\n# Show the chart\nchart.show()\n</code></pre> Source code in <code>uptrain/operators/chart.py</code> <pre><code>@register_op\nclass BarChart(Chart):\n\"\"\"\n    Operator to generate a bar chart.\n\n    Attributes:\n        props (dict): Additional properties to pass to the BarChart constructor.\n        x (str): The name of the column to use for the x-axis.\n        y (str): The name of the column to use for the y-axis.\n        color (str): The name of the column to use for the color.\n        barmode (str): The type of bar chart to generate.\n        title (str): The title of the chart.\n\n    Returns:\n        dict: A dictionary containing the chart object.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import BarChart\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"x\": [1, 2, 3, 4, 5],\n            \"y\": [10, 20, 15, 25, 30]\n        })\n\n        # Create a bar chart using the BarChart class\n        bar_chart = BarChart(x=\"x\", y=\"y\", title=\"Bar Chart\")\n\n        # Generate the bar chart\n        chart = bar_chart.run(df)[\"extra\"][\"chart\"]\n\n        # Show the chart\n        chart.show()\n        ```\n\n    \"\"\"\n\n\n    props: dict = Field(default_factory=dict)\n    title: str = \"\"\n    x: str = \"\"\n    y: str = \"\"\n    color: str = \"\"\n    barmode: str = \"group\"\n\n    kind = \"bar\"\n</code></pre>"},{"location":"operators/charts/CustomPlotlyChart/","title":"CustomPlotlyChart","text":"<p>             Bases: <code>Chart</code></p> <p>Operator to generate a custom plotly chart, other than the ones provided by uptrain.</p> <p>Attributes:</p> Name Type Description <code>props</code> <code>dict</code> <p>Additional properties to pass to the PlotlyChart constructor.</p> <code>title</code> <code>str</code> <p>The title of the chart.</p> <code>x</code> <code>str</code> <p>The name of the column to use for the x-axis.</p> <code>y</code> <code>str</code> <p>The name of the column to use for the y-axis.</p> <code>color</code> <code>str</code> <p>The name of the column to use for the color.</p> <code>kind</code> <code>str</code> <p>The type of chart to generate.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the chart object.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import CustomPlotlyChart\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"x\": [1, 2, 3, 4, 5],\n    \"y\": [10, 20, 15, 25, 30]\n})\n\n# Create a funnel chart using the CustomPlotlyChart class\nfunnel_chart = CustomPlotlyChart(x=\"x\", y=\"y\", title=\"Funnel Chart\")\n\n# Generate the funnel chart\nchart = funnel_chart.run(df)[\"extra\"][\"chart\"]\n\n# Show the chart\nchart.show()\n</code></pre> Source code in <code>uptrain/operators/chart.py</code> <pre><code>@register_op\nclass CustomPlotlyChart(Chart):\n\"\"\"\n    Operator to generate a custom plotly chart, other than the ones provided by uptrain.\n\n    Attributes:\n        props (dict): Additional properties to pass to the PlotlyChart constructor.\n        title (str): The title of the chart.\n        x (str): The name of the column to use for the x-axis.\n        y (str): The name of the column to use for the y-axis.\n        color (str): The name of the column to use for the color.\n        kind (str): The type of chart to generate.\n\n    Returns:\n        dict: A dictionary containing the chart object.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import CustomPlotlyChart\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"x\": [1, 2, 3, 4, 5],\n            \"y\": [10, 20, 15, 25, 30]\n        })\n\n        # Create a funnel chart using the CustomPlotlyChart class\n        funnel_chart = CustomPlotlyChart(x=\"x\", y=\"y\", title=\"Funnel Chart\")\n\n        # Generate the funnel chart\n        chart = funnel_chart.run(df)[\"extra\"][\"chart\"]\n\n        # Show the chart\n        chart.show()\n        ```\n\n    \"\"\"\n\n    props: dict = Field(default_factory=dict)\n    title: str = \"\"\n    x: str = \"\"\n    y: str = \"\"\n    color: str = \"\"\n    kind: str = Field(default_factory=str)\n</code></pre>"},{"location":"operators/charts/Histogram/","title":"Histogram","text":"<p>             Bases: <code>Chart</code></p> <p>Operator to generate a histogram.</p> <p>Attributes:</p> Name Type Description <code>props</code> <code>dict</code> <p>Additional properties to pass to the Histogram chart constructor.</p> <code>title</code> <code>str</code> <p>The title of the chart.</p> <code>x</code> <code>str</code> <p>The name of the column to use for the x-axis.</p> <code>y</code> <code>str</code> <p>The name of the column to use for the y-axis.</p> <code>color</code> <code>str</code> <p>The name of the column to use for the color.</p> <code>nbins</code> <code>int</code> <p>The maximum number of bins to use for the histogram.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the chart object.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import Histogram\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"x\": [1, 2, 3, 4, 5],\n    \"y\": [10, 20, 15, 25, 30]\n})\n\n# Create a histogram chart using the Histogram class\nhistogram_chart = Histogram(x=\"x\", y=\"y\", title=\"Histogram Chart\")\n\n# Generate the histogram chart\nchart = histogram_chart.run(df)[\"extra\"][\"chart\"]\n\n# Show the chart\nchart.show()\n</code></pre> Source code in <code>uptrain/operators/chart.py</code> <pre><code>@register_op\nclass Histogram(Chart):\n\"\"\"\n    Operator to generate a histogram.\n\n    Attributes:\n        props (dict): Additional properties to pass to the Histogram chart constructor.\n        title (str): The title of the chart.\n        x (str): The name of the column to use for the x-axis.\n        y (str): The name of the column to use for the y-axis.\n        color (str): The name of the column to use for the color.\n        nbins (int): The maximum number of bins to use for the histogram.\n\n    Returns:\n        dict: A dictionary containing the chart object.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import Histogram\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"x\": [1, 2, 3, 4, 5],\n            \"y\": [10, 20, 15, 25, 30]\n        })\n\n        # Create a histogram chart using the Histogram class\n        histogram_chart = Histogram(x=\"x\", y=\"y\", title=\"Histogram Chart\")\n\n        # Generate the histogram chart\n        chart = histogram_chart.run(df)[\"extra\"][\"chart\"]\n\n        # Show the chart\n        chart.show()\n        ```\n\n    \"\"\"\n\n\n    props: dict = Field(default_factory=dict)\n    title: str = \"\"\n    x: str = \"\"\n    y: str = \"\"\n    color: str = \"\"\n    nbins: int = 20\n\n    kind = \"histogram\"\n</code></pre>"},{"location":"operators/charts/LineChart/","title":"LineChart","text":"<p>             Bases: <code>Chart</code></p> <p>Operator to generate a line chart.</p> <p>Attributes:</p> Name Type Description <code>props</code> <code>dict</code> <p>Additional properties to pass to the LineChart constructor.</p> <code>x</code> <code>str</code> <p>The name of the column to use for the x-axis.</p> <code>y</code> <code>str</code> <p>The name of the column to use for the y-axis.</p> <code>color</code> <code>str</code> <p>The name of the column to use for the color.</p> <code>title</code> <code>str</code> <p>The title of the chart.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the chart object.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import LineChart\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"x\": [1, 2, 3, 4, 5],\n    \"y\": [10, 20, 15, 25, 30]\n})\n\n# Create a line chart using the LineChart class\nline_chart = LineChart(x=\"x\", y=\"y\", title=\"Line Chart\")\n\n# Generate the line chart\nchart = line_chart.run(df)[\"extra\"][\"chart\"]\n\n# Show the chart\nchart.show()\n</code></pre> Source code in <code>uptrain/operators/chart.py</code> <pre><code>@register_op\nclass LineChart(Chart):\n\"\"\"\n    Operator to generate a line chart.\n\n    Attributes:\n        props (dict): Additional properties to pass to the LineChart constructor.\n        x (str): The name of the column to use for the x-axis.\n        y (str): The name of the column to use for the y-axis.\n        color (str): The name of the column to use for the color.\n        title (str): The title of the chart.\n\n    Returns:\n        dict: A dictionary containing the chart object.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import LineChart\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"x\": [1, 2, 3, 4, 5],\n            \"y\": [10, 20, 15, 25, 30]\n        })\n\n        # Create a line chart using the LineChart class\n        line_chart = LineChart(x=\"x\", y=\"y\", title=\"Line Chart\")\n\n        # Generate the line chart\n        chart = line_chart.run(df)[\"extra\"][\"chart\"]\n\n        # Show the chart\n        chart.show()\n        ```\n\n    \"\"\"\n\n\n    props: dict = Field(default_factory=dict)\n    title: str = \"\"\n    x: str = \"\"\n    y: str = \"\"\n    color: str = \"\"\n\n    kind = \"line\"\n</code></pre>"},{"location":"operators/charts/MultiPlot/","title":"MultiPlot","text":"<p>             Bases: <code>Chart</code></p> <p>Operator to generate a subplot that can display multiple charts side-by-side.</p> <p>Attributes:</p> Name Type Description <code>props</code> <code>dict</code> <p>Additional properties to pass to the MultiPlot constructor.</p> <code>title</code> <code>str</code> <p>The title of the chart.</p> <code>charts</code> <code>list</code> <p>A list of charts to display in the subplot.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the chart object.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import MultiPlot, LineChart, ScatterPlot, BarChart, Histogram\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"x\": [1, 2, 3, 4, 5],\n    \"y\": [10, 20, 15, 25, 30]\n})\n\n# Create a multiplot using the MultiPlot class\nmultiplot = MultiPlot(\n    props={},\n    charts=[\n        LineChart(\n            x=\"x\",\n            y=\"y\", \n            title=\"Line Chart\"\n        ),\n        ScatterPlot(\n            x=\"x\",\n            y=\"y\",\n            title=\"Scatter Plot\"\n        ),\n        BarChart(\n            x=\"x\",\n            y=\"y\",\n            title=\"Bar Chart\"\n        ),\n        Histogram(\n            x=\"x\",\n            y=\"y\",\n            title=\"Histogram\"\n        )\n    ],\n    title=\"MultiPlot\",\n)\n\n# Generate the multiplot\nchart = multiplot.run(df)[\"extra\"][\"chart\"]\n\n# Show the chart\nchart.show()\n</code></pre> Source code in <code>uptrain/operators/chart.py</code> <pre><code>@register_op\nclass MultiPlot(Chart):\n\"\"\"\n    Operator to generate a subplot that can display multiple charts side-by-side.\n\n    Attributes:\n        props (dict): Additional properties to pass to the MultiPlot constructor.\n        title (str): The title of the chart.\n        charts (list): A list of charts to display in the subplot.\n\n    Returns:\n        dict: A dictionary containing the chart object.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import MultiPlot, LineChart, ScatterPlot, BarChart, Histogram\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"x\": [1, 2, 3, 4, 5],\n            \"y\": [10, 20, 15, 25, 30]\n        })\n\n        # Create a multiplot using the MultiPlot class\n        multiplot = MultiPlot(\n            props={},\n            charts=[\n                LineChart(\n                    x=\"x\",\n                    y=\"y\", \n                    title=\"Line Chart\"\n                ),\n                ScatterPlot(\n                    x=\"x\",\n                    y=\"y\",\n                    title=\"Scatter Plot\"\n                ),\n                BarChart(\n                    x=\"x\",\n                    y=\"y\",\n                    title=\"Bar Chart\"\n                ),\n                Histogram(\n                    x=\"x\",\n                    y=\"y\",\n                    title=\"Histogram\"\n                )\n            ],\n            title=\"MultiPlot\",\n        )\n\n        # Generate the multiplot\n        chart = multiplot.run(df)[\"extra\"][\"chart\"]\n\n        # Show the chart\n        chart.show()\n        ```\n\n    \"\"\"\n\n    props: dict = Field(default_factory=dict)\n    title: str = \"\"\n    charts: list\n\n    kind = \"multiplot\"\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        if type(self.charts[0]) == dict:\n            self.charts = [Chart(**chart).setup() for chart in self.charts]\n        subplot = ps.make_subplots(\n            rows=1,\n            cols=len(self.charts),\n            subplot_titles=[chart.title for chart in self.charts],\n        )\n\n        for chart in self.charts:\n            plot = getattr(px, chart.kind)(data.to_pandas(), **chart.props)\n            subplot.add_trace(plot.to_dict()[\"data\"][0], row=1, col=self.charts.index(chart) + 1)\n\n        subplot.update_layout(title_text=self.title)\n        return {\"output\": None, \"extra\": {\"chart\": subplot}}\n</code></pre>"},{"location":"operators/charts/ScatterPlot/","title":"ScatterPlot","text":"<p>             Bases: <code>Chart</code></p> <p>Operator to generate a scatter chart.</p> <p>Attributes:</p> Name Type Description <code>props</code> <code>dict</code> <p>Additional properties to pass to the ScatterPlot constructor.</p> <code>title</code> <code>str</code> <p>The title of the chart.</p> <code>x</code> <code>str</code> <p>The name of the column to use for the x-axis.</p> <code>y</code> <code>str</code> <p>The name of the column to use for the y-axis.</p> <code>color</code> <code>str</code> <p>The name of the column to use for the color.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the chart object.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import ScatterPlot\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"x\": [1, 2, 3, 4, 5],\n    \"y\": [10, 20, 15, 25, 30]\n})\n\n# Create a scatter chart using the ScatterPlot class\nscatter_plot = ScatterPlot(x=\"x\", y=\"y\", title=\"Scatter Plot\")\n\n# Generate the scatter plot\nchart = scatter_plot.run(df)[\"extra\"][\"chart\"]\n\n# Show the chart\nchart.show()\n</code></pre> Source code in <code>uptrain/operators/chart.py</code> <pre><code>@register_op\nclass ScatterPlot(Chart):\n\"\"\"\n    Operator to generate a scatter chart.\n\n    Attributes:\n        props (dict): Additional properties to pass to the ScatterPlot constructor.\n        title (str): The title of the chart.\n        x (str): The name of the column to use for the x-axis.\n        y (str): The name of the column to use for the y-axis.\n        color (str): The name of the column to use for the color.\n\n    Returns:\n        dict: A dictionary containing the chart object.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import ScatterPlot\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"x\": [1, 2, 3, 4, 5],\n            \"y\": [10, 20, 15, 25, 30]\n        })\n\n        # Create a scatter chart using the ScatterPlot class\n        scatter_plot = ScatterPlot(x=\"x\", y=\"y\", title=\"Scatter Plot\")\n\n        # Generate the scatter plot\n        chart = scatter_plot.run(df)[\"extra\"][\"chart\"]\n\n        # Show the chart\n        chart.show()\n        ```\n\n    \"\"\"\n\n\n    props: dict = Field(default_factory=dict)\n    title: str = \"\"\n    x: str = \"\"\n    y: str = \"\"\n    color: str = \"\"\n    symbol: str = \"circle\"\n\n    kind = \"scatter\"\n</code></pre>"},{"location":"operators/code/SQL/ExecuteAndCompareSQL/","title":"ExecuteAndCompareSQL","text":"<p>             Bases: <code>TransformOp</code></p> <p>Execute predicted SQL, ground truth SQL and compute execution accuracy of the predicted sql.</p> <p>For now, we expect the output to exactly match along with the column names.</p> <p>ignore_column_order, ignore_row_order params attempt to do a semantic match by ignoring the order. This allows us to correctly compare <code>SELECT a,b</code> and <code>SELECT b,a</code> if the column order is not important. However, the intent in the text query also needs to be taken in consideration for correct sematic match.</p> <p>Attributes:</p> Name Type Description <code>col_in_response_sql</code> <code>str</code> <p>Column containing response SQL.</p> <code>col_in_gt_sql</code> <code>str</code> <p>Column containing schema definition tables and columns as a json dict Table -&gt; [columns].</p> <code>col_in_db_path</code> <code>str</code> <p>Column to store if tables are valid.</p> <code>col_out_execution_accuracy</code> <code>str</code> <p>Column to store if columns are valid.</p> <code>ignore_column_order</code> <code>bool</code> <p>Boolean param to ignore column order when comparing SQL output. True by default.</p> <code>ignore_row_order</code> <code>bool</code> <p>Boolean param to ignore row order when comparing SQL output. True by default.</p> Source code in <code>uptrain/operators/code/sql.py</code> <pre><code>@register_op\nclass ExecuteAndCompareSQL(TransformOp):\n\"\"\"\n    Execute predicted SQL, ground truth SQL and compute execution accuracy of the predicted sql.\n\n    For now, we expect the output to exactly match along with the column names.\n\n    ignore_column_order, ignore_row_order params attempt to do a semantic match by ignoring the order. This allows us to\n    correctly compare `SELECT a,b` and `SELECT b,a` if the column order is not important. However, the intent in the\n    text query also needs to be taken in consideration for correct sematic match.\n\n    Attributes:\n        col_in_response_sql (str): Column containing response SQL.\n        col_in_gt_sql (str): Column containing schema definition tables and columns as a json dict Table -&gt; [columns].\n        col_in_db_path (str): Column to store if tables are valid.\n        col_out_execution_accuracy (str): Column to store if columns are valid.\n        ignore_column_order (bool): Boolean param to ignore column order when comparing SQL output. True by default.\n        ignore_row_order (bool): Boolean param to ignore row order when comparing SQL output. True by default.\n\n    \"\"\"\n\n    col_in_response_sql: str\n    col_in_gt_sql: str\n    col_in_db_path: str\n    col_out_execution_accuracy: str\n    ignore_column_order: bool = True\n    ignore_row_order: bool = True\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        response_sqls = data.get_column(self.col_in_response_sql)\n        gt_sqls = data.get_column(self.col_in_gt_sql)\n        db_paths = data.get_column(self.col_in_db_path)\n        results = []\n        for response_sql, gt_sql, db_path in zip(response_sqls, gt_sqls, db_paths):\n            results.append(\n                execute_and_compare_sql(\n                    response_sql,\n                    gt_sql,\n                    db_path,\n                    ignore_column_order=self.ignore_column_order,\n                    ignore_row_order=self.ignore_row_order,\n                )\n            )\n        return {\n            \"output\": data.with_columns(\n                [pl.Series(self.col_out_execution_accuracy, results)]\n            )\n        }\n</code></pre>"},{"location":"operators/code/SQL/ParseCreateStatements/","title":"ParseCreateStatements","text":"<p>             Bases: <code>TransformOp</code></p> <p>Read tables and columns from \";\" separated CREATE TABLE statements and writes a json dictionary Table -&gt; [columns].</p> <p>Attributes:</p> Name Type Description <code>col_in_schema_def</code> <code>str</code> <p>Column name of schema def containing CREATE TABLE statements.</p> <code>col_out_tables</code> <code>str</code> <p>Column to write parsed tables and columns.</p> Source code in <code>uptrain/operators/code/sql.py</code> <pre><code>@register_op\nclass ParseCreateStatements(TransformOp):\n\"\"\"\n    Read tables and columns from \";\" separated CREATE TABLE statements and writes a json dictionary Table -&gt; [columns].\n\n    Attributes:\n        col_in_schema_def (str): Column name of schema def containing CREATE TABLE statements.\n        col_out_tables (str): Column to write parsed tables and columns.\n\n    \"\"\"\n\n    col_in_schema_def: str\n    col_out_tables: str\n\n    def setup(self, settings: Settings):\n        return self\n\n    def __fetch_tables_columns(self, create_statements) -&gt; t.Tuple(str, str, str):\n        tables_and_columns = {}\n        # SQL statements are separated by ';'\n        statements = create_statements.split(\";\")\n\n        # Create table statements\n        for statement in statements:\n            if statement.upper().strip().startswith(\"CREATE TABLE\"):\n                # Add the statement to the list\n                statement = statement.strip()\n                # TODO: handle input database dialect instead of assuming it.\n                parsed = sqlglot.parse(statement, read=sqlglot.Dialects.SQLITE)\n                table, columns = extract_tables_and_columns_from_create(parsed[0])\n                tables_and_columns[table] = list(columns)\n\n        return json.dumps(tables_and_columns)\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        schemas = data.get_column(self.col_in_schema_def)\n        tables = [self.__fetch_tables_columns(schema) for schema in schemas]\n        return {\"output\": data.with_columns([pl.Series(self.col_out_tables, tables)])}\n</code></pre>"},{"location":"operators/code/SQL/ParseSQL/","title":"ParseSQL","text":"<p>             Bases: <code>TransformOp</code></p> <p>Read tables and columns from a generic SQL SELECT statement and writes a json dictionary Table -&gt; [columns]. Note that we don't use table schema definition to do this but instead simply parse the SQL. Output might have a placeholder table to include columns that are accessed without a table descriptor.</p> <p>This is typically used along with ValidateTables to validate tables and columns in the predicted SQL.</p> <p>Attributes:</p> Name Type Description <code>col_in_sql</code> <code>str</code> <p>Column of input SQL containing SQL SELECT statement.</p> <code>col_out_tables</code> <code>str</code> <p>Column to write parsed tables and columns.</p> <code>col_out_is_valid_sql</code> <code>str</code> <p>Column to store if sql is valid as per sql parser.</p> Source code in <code>uptrain/operators/code/sql.py</code> <pre><code>@register_op\nclass ParseSQL(TransformOp):\n\"\"\"\n    Read tables and columns from a generic SQL SELECT statement and writes a json dictionary Table -&gt; [columns].\n    Note that we don't use table schema definition to do this but instead simply parse the SQL. Output might have a\n    placeholder table to include columns that are accessed without a table descriptor.\n\n    This is typically used along with ValidateTables to validate tables and columns in the predicted SQL.\n\n    Attributes:\n        col_in_sql (str): Column of input SQL containing SQL SELECT statement.\n        col_out_tables (str): Column to write parsed tables and columns.\n        col_out_is_valid_sql (str): Column to store if sql is valid as per sql parser.\n\n    \"\"\"\n\n    col_in_sql: str\n    col_out_tables: str\n    col_out_is_valid_sql: str\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        sqls = data.get_column(self.col_in_sql)\n        tables = []\n        is_valid = []\n        for sql in sqls:\n            try:\n                # TODO: parse using expected dialect\n                parsed = sqlglot.parse(sql)\n                tables_and_columns = extract_tables_and_columns(parsed[0])\n                # Since sets are not serializable, convert to list\n                for table, columns in tables_and_columns.items():\n                    tables_and_columns[table] = list(columns)\n                tables.append(json.dumps(tables_and_columns))\n                is_valid.append(True)\n            except sqlglot.errors.ParseError:\n                tables.append(json.dumps({}))\n                is_valid.append(False)\n\n        return {\n            \"output\": data.with_columns(\n                [\n                    pl.Series(self.col_out_tables, tables),\n                    pl.Series(self.col_out_is_valid_sql, is_valid),\n                ]\n            )\n        }\n</code></pre>"},{"location":"operators/code/SQL/ValidateTables/","title":"ValidateTables","text":"<p>             Bases: <code>TransformOp</code></p> <p>Ensures that table and column names from response/predicted SQL are valid tables columns as per the schema definition.</p> <p>This is typically used with ParseSQL and ParseCreateStatements.</p> <p>Attributes:</p> Name Type Description <code>col_in_response_tables</code> <code>str</code> <p>Column containing response SQL tables and columns as a json dict Table -&gt; [columns].</p> <code>col_in_schema_tables</code> <code>str</code> <p>Column containing schema definition tables and columns as a json dict Table -&gt; [columns].</p> <code>col_out_is_tables_valid</code> <code>str</code> <p>Column to store if tables are valid.</p> <code>col_out_is_cols_valid</code> <code>str</code> <p>Column to store if columns are valid.</p> Source code in <code>uptrain/operators/code/sql.py</code> <pre><code>@register_op\nclass ValidateTables(TransformOp):\n\"\"\"\n    Ensures that table and column names from response/predicted SQL are valid tables columns as per the schema\n    definition.\n\n    This is typically used with ParseSQL and ParseCreateStatements.\n\n    Attributes:\n        col_in_response_tables (str): Column containing response SQL tables and columns as a json dict Table -&gt; [columns].\n        col_in_schema_tables (str): Column containing schema definition tables and columns as a json dict Table -&gt; [columns].\n        col_out_is_tables_valid (str): Column to store if tables are valid.\n        col_out_is_cols_valid (str): Column to store if columns are valid.\n\n    \"\"\"\n\n    col_in_response_tables: str\n    col_in_schema_tables: str\n    col_out_is_tables_valid: str\n    col_out_is_cols_valid: str\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        response_tables = data.get_column(self.col_in_response_tables)\n        schema_tables = data.get_column(self.col_in_schema_tables)\n        results = []\n        results_column = []\n        for response_table, schema_table in zip(response_tables, schema_tables):\n            is_valid_table = True\n            is_valid_column = True\n            # deserialize json\n            s = json.loads(schema_table)\n            r = json.loads(response_table)\n            columns_list = [columns for table, columns in s.items()]\n            all_columns = set(itertools.chain(*columns_list))\n            for table, columns in r.items():\n                is_valid_table &amp;= table == PLACEHOLDER_TABLE or table in s\n                # TODO: handle aliases and do lineage check\n                is_valid_column = (\n                    is_valid_column\n                    and is_valid_table\n                    and (\n                        (\n                            table != PLACEHOLDER_TABLE\n                            and set(columns).issubset(set(s[table]))\n                        )\n                        or (\n                            table == PLACEHOLDER_TABLE\n                            and set(columns).issubset(all_columns)\n                        )\n                    )\n                )\n\n            results.append(is_valid_table)\n            results_column.append(is_valid_column)\n        return {\n            \"output\": data.with_columns(\n                [\n                    pl.Series(self.col_out_is_tables_valid, results),\n                    pl.Series(self.col_out_is_cols_valid, results_column),\n                ]\n            )\n        }\n</code></pre>"},{"location":"operators/language/DocsLinkVersion/","title":"DocsLinkVersion","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator to extract version numbers from URLs in text data.</p> <p>Attributes:</p> Name Type Description <code>domain_name</code> <code>str</code> <p>Filter down to links from this domain. Defaults to None.</p> <code>col_in_text</code> <code>str</code> <p>The name of the input column containing the text data.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the extracted version numbers.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import DocsLinkVersion\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"text\": [\"https://docs.streamlit.io/1.9.0/library/api-reference/charts/st.plotly_chart#stplotly_chart\", \"No version here\"]\n})\n\n# Create an instance of the DocsLinkVersion class\nlink_op = DocsLinkVersion(col_in_text=\"text\")\n\n# Extract the version numbers\nversions = link_op.run(df)[\"output\"]\n\n# Print the extracted version numbers\nprint(versions)\n</code></pre> Output <pre><code>shape: (2,)\nSeries: '_col_0' [str]\n[\n        \"1.9.0\"\n        null\n]\n</code></pre> Source code in <code>uptrain/operators/language/text.py</code> <pre><code>@register_op\nclass DocsLinkVersion(ColumnOp):\n\"\"\"\n    Operator to extract version numbers from URLs in text data.\n\n    Attributes:\n        domain_name (str, optional): Filter down to links from this domain. Defaults to None.\n        col_in_text (str): The name of the input column containing the text data.\n\n    Returns:\n        dict: A dictionary containing the extracted version numbers.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import DocsLinkVersion\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"text\": [\"https://docs.streamlit.io/1.9.0/library/api-reference/charts/st.plotly_chart#stplotly_chart\", \"No version here\"]\n        })\n\n        # Create an instance of the DocsLinkVersion class\n        link_op = DocsLinkVersion(col_in_text=\"text\")\n\n        # Extract the version numbers\n        versions = link_op.run(df)[\"output\"]\n\n        # Print the extracted version numbers\n        print(versions)\n        ```\n\n    Output:\n        ```\n        shape: (2,)\n        Series: '_col_0' [str]\n        [\n                \"1.9.0\"\n                null\n        ]\n        ```\n\n    \"\"\"\n\n    domain_name: t.Optional[str] = None  # filter down to links from this domain\n    col_in_text: str\n    col_out: str = \"docs_link_version\"\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        def fetch_version(text):\n            for link in extract_links(text, self.domain_name):\n                v = extract_version(link)\n                if v is not None:\n                    return v\n            return None\n\n        results = data.get_column(self.col_in_text).apply(fetch_version)\n        return {\"output\": data.with_columns([results.alias(self.col_out)])}\n</code></pre>"},{"location":"operators/language/Embedding/","title":"Embedding","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Column operation that generates embeddings for text using pre-trained models.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>Literal['MiniLM-L6-v2', 'hkunlp/instructor-xl']</code> <p>The name of the pre-trained model to use.</p> <code>col_in_text</code> <code>str</code> <p>The name of the text column in the DataFrame.</p> <code>col_out</code> <code>str</code> <p>The name of the output column in the DataFrame.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the specified model is not supported.</p> <p>Returns:</p> Name Type Description <code>TYPE_TABLE_OUTPUT</code> <p>A dictionary containing the generated embeddings.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import Embedding\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"text\": [\"This is the first sentence.\", \"Here is another sentence.\"]\n})\n\n# Create an instance of the Embedding class\nembedding_op = Embedding(model=\"MiniLM-L6-v2\", col_in_text=\"text\")\n\n# Set up the Embedding operator\nembedding_op.setup()\n\n# Generate embeddings for the text column\nembeddings = embedding_op.run(df)[\"output\"]\n\n# Print the embeddings\nprint(embeddings)\n</code></pre> Output <pre><code>shape: (2,)\nSeries: '_col_0' [list[f32]]\n[\n        [0.098575, 0.056978, \u2026 -0.071038]\n        [0.072772, 0.073564, \u2026 -0.043947]\n]\n</code></pre> Source code in <code>uptrain/operators/language/embedding.py</code> <pre><code>@register_op\nclass Embedding(ColumnOp):\n\"\"\"\n    Column operation that generates embeddings for text using pre-trained models.\n\n    Attributes:\n        model (Literal[\"MiniLM-L6-v2\", \"hkunlp/instructor-xl\"]): The name of the pre-trained model to use.\n        col_in_text (str): The name of the text column in the DataFrame.\n        col_out (str): The name of the output column in the DataFrame.\n\n    Raises:\n        Exception: If the specified model is not supported.\n\n    Returns:\n        TYPE_TABLE_OUTPUT: A dictionary containing the generated embeddings.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import Embedding\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"text\": [\"This is the first sentence.\", \"Here is another sentence.\"]\n        })\n\n        # Create an instance of the Embedding class\n        embedding_op = Embedding(model=\"MiniLM-L6-v2\", col_in_text=\"text\")\n\n        # Set up the Embedding operator\n        embedding_op.setup()\n\n        # Generate embeddings for the text column\n        embeddings = embedding_op.run(df)[\"output\"]\n\n        # Print the embeddings\n        print(embeddings)\n        ```\n\n    Output:\n        ```\n        shape: (2,)\n        Series: '_col_0' [list[f32]]\n        [\n                [0.098575, 0.056978, \u2026 -0.071038]\n                [0.072772, 0.073564, \u2026 -0.043947]\n        ]\n        ```\n\n    \"\"\"\n\n    model: t.Literal[\"MiniLM-L6-v2\", \"hkunlp/instructor-xl\"]\n    col_in_text: str = \"text\"\n    col_out: str = \"embedding\"\n\n    def setup(self, settings: Settings):\n        if self.model == \"hkunlp/instructor-xl\":\n            self._model_obj = InstructorEmbedding.INSTRUCTOR(self.model)  # type: ignore\n        elif self.model == \"MiniLM-L6-v2\":\n            self._model_obj = sentence_transformers.SentenceTransformer(\n                \"sentence-transformers/all-MiniLM-L6-v2\"\n            )  # type: ignore\n        else:\n            raise Exception(f\"Embeddings model: {self.model} is not supported yet.\")\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        text = data.get_column(self.col_in_text)\n        if self.model == \"hkunlp/instructor-xl\":\n            inputs = [\n                [\"Represent the developer documentation sentence: \", x] for x in text\n            ]\n        elif self.model == \"MiniLM-L6-v2\":\n            inputs = list(text)\n        else:\n            raise Exception(\"Embeddings model not supported\")\n        results = self._model_obj.encode(inputs)\n\n        return {\"output\": data.with_columns([pl.Series(results).alias(self.col_out)])}\n</code></pre>"},{"location":"operators/language/GrammarScore/","title":"GrammarScore","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator to test the grammatical correctness of sentences using the OpenAI GPT-3.5-turbo language model.</p> <p>Attributes:</p> Name Type Description <code>col_in_text</code> <code>str</code> <p>The name of the input column containing the sentences to evaluate.</p> <code>col_out</code> <code>str</code> <p>The name of the output column containing the grammar scores.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the grammar scores for each input sentence.</p> Source code in <code>uptrain/operators/language/grammar.py</code> <pre><code>@register_op\nclass GrammarScore(ColumnOp):\n\"\"\"\n    Operator to test the grammatical correctness of sentences using the OpenAI GPT-3.5-turbo language model.\n\n    Attributes:\n        col_in_text (str): The name of the input column containing the sentences to evaluate.\n        col_out (str): The name of the output column containing the grammar scores.\n\n    Returns:\n        dict: A dictionary containing the grammar scores for each input sentence.\n\n    \"\"\"\n\n    col_in_text: str = \"text\"\n    col_out: str = \"grammar_score\"\n\n    def setup(self, settings: t.Optional[Settings] = None):\n        self._api_client = LLMMulticlient(settings=settings)\n        return self\n\n    def _make_payload(self, id: t.Any, text: str) -&gt; Payload:\n        return Payload(\n            endpoint=\"chat.completions\",\n            data={\n                \"model\": \"gpt-3.5-turbo\",\n                \"messages\": [\n                    {\n                        \"role\": \"system\",\n                        \"content\": \"You are a grammatical correctness evaluator who produces only a number and no explanation.\",\n                    },\n                    {\n                        \"role\": \"user\",\n                        \"content\": \"Score following sentence on grammatical correctness on a scale of 0 to 100: \\n\\n {statement}\".format(\n                            statement=text\n                        ),\n                    },\n                ],\n            },\n            metadata={\"index\": id},\n        )\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        text_ser = data.get_column(self.col_in_text)\n        input_payloads = [\n            self._make_payload(idx, text) for idx, text in enumerate(text_ser)\n        ]\n        output_payloads = self._api_client.fetch_responses(input_payloads)\n\n        results = []\n        for res in output_payloads:\n            assert (\n                res is not None\n            ), \"Response should not be None, we should've handled exceptions beforehand.\"\n            idx = res.metadata[\"index\"]\n            if res.error is not None:\n                logger.error(\n                    f\"Error when processing payload at index {idx}: {res.error}\"\n                )\n                results.append((idx, None))\n            else:\n                resp_text = res.response[\"choices\"][0][\"message\"][\"content\"]\n                number = int(re.findall(r\"\\d+\", resp_text)[0])\n                results.append((idx, number))\n\n        result_scores = pl.Series(\n            [val for _, val in sorted(results, key=lambda x: x[0])]\n        )\n        return {\"output\": data.with_columns([result_scores.alias(self.col_out)])}\n</code></pre>"},{"location":"operators/language/LLM/","title":"LLM","text":"<p>Implement checks to test language quality.</p>"},{"location":"operators/language/LLM/#uptrain.operators.language.llm.LLMMulticlient","title":"<code>LLMMulticlient</code>","text":"<p>Use multiple threads to send requests to the OpenAI API concurrently.</p> Source code in <code>uptrain/operators/language/llm.py</code> <pre><code>class LLMMulticlient:\n\"\"\"\n    Use multiple threads to send requests to the OpenAI API concurrently.\n    \"\"\"\n\n    def __init__(self, settings: t.Optional[Settings] = None):\n        self._max_tries = 4\n        self._rpm_limit = 20\n        if settings is not None:\n            openai.api_key = settings.check_and_get(\"openai_api_key\")  # type: ignore\n            self._rpm_limit = settings.check_and_get(\"openai_rpm_limit\")\n\n    def fetch_responses(self, input_payloads: list[Payload]) -&gt; list[Payload]:\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            loop = None\n\n        if loop and loop.is_running():\n            logger.warning(\n                \"Detected Jupyter environment, scheduling requests in a separate thread.\"\n            )\n            with ThreadPoolExecutor(max_workers=1) as executor:\n                return executor.submit(\n                    asyncio.run, self.async_fetch_responses(input_payloads)\n                ).result()\n        else:\n            return asyncio.run(self.async_fetch_responses(input_payloads))\n\n    async def async_fetch_responses(\n        self, input_payloads: list[Payload]\n    ) -&gt; list[Payload]:\n        limiter = aiolimiter.AsyncLimiter(self._rpm_limit, time_period=1)\n        async_outputs = [\n            async_process_payload(data, limiter, self._max_tries)\n            for data in input_payloads\n        ]\n        output_payloads = await tqdm_asyncio.gather(*async_outputs)\n        return output_payloads\n</code></pre>"},{"location":"operators/language/ModelGradeScore/","title":"ModelGradeScore","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator to calculate the grade score of text completions using a custom prompt for grading. It is a wrapper using the same utilities from the OpenAI evals library, replacing just the completion call.</p> <p>Attributes:</p> Name Type Description <code>grading_prompt_template</code> <code>str</code> <p>Template for the grading prompt.</p> <code>eval_type</code> <code>Literal['cot_classify', 'classify', 'classify_cot']</code> <p>The type of evaluation for grading (\"cot_classify\" by default).</p> <code>choice_strings</code> <code>list[str]</code> <p>The list of choice strings for grading.</p> <code>choice_scores</code> <code>dict[str, float]</code> <p>The dictionary mapping choice strings to scores.</p> <code>context_vars</code> <code>dict[str, str]</code> <p>A dictionary mapping context variable names to corresponding columns in the input dataset.</p> Source code in <code>uptrain/operators/language/model_grade.py</code> <pre><code>@register_op\nclass ModelGradeScore(ColumnOp):\n\"\"\"\n    Operator to calculate the grade score of text completions using a custom prompt\n    for grading. It is a wrapper using the same utilities from the OpenAI evals library,\n    replacing just the completion call.\n\n    Attributes:\n        grading_prompt_template (str): Template for the grading prompt.\n        eval_type (Literal[\"cot_classify\", \"classify\", \"classify_cot\"]): The type of evaluation for grading (\"cot_classify\" by default).\n        choice_strings (list[str]): The list of choice strings for grading.\n        choice_scores (dict[str, float]): The dictionary mapping choice strings to scores.\n        context_vars (dict[str, str]): A dictionary mapping context variable names to corresponding\n            columns in the input dataset.\n    \"\"\"\n\n    grading_prompt_template: str\n    eval_type: t.Literal[\"cot_classify\", \"classify\", \"classify_cot\"] = \"cot_classify\"\n    choice_strings: list[str]\n    choice_scores: t.Union[dict[str, float], dict[str, list[float]]]\n    context_vars: dict[str, str]\n    col_out: t.Union[str, list[str]] = \"model_grade_score\"\n\n    def setup(self, settings: Settings):\n        self._api_client = LLMMulticlient(settings=settings)\n        return self\n\n    def _make_payload(self, id: t.Any, messages: list[dict]) -&gt; Payload:\n        return Payload(\n            endpoint=\"chat.completions\",\n            data={\"model\": \"gpt-3.5-turbo\", \"messages\": messages, \"temperature\": 0.2},\n            metadata={\"index\": id},\n        )\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        prompts = []\n        for row in data.rows(named=True):\n            subs = {k: row[v] for k, v in self.context_vars.items()}\n            # fill in context variables in the prompt template\n            _prompt = self.grading_prompt_template.format(**subs)\n            # following the `evals` code to create the grading instruction\n            #  https://github.com/openai/evals/blob/main/evals/elsuite/modelgraded/classify_utils.py\n            _prompt_chat = append_answer_prompt(\n                prompt=[{\"role\": \"user\", \"content\": _prompt}],\n                eval_type=self.eval_type,\n                choice_strings=self.choice_strings,\n            )\n            prompts.append(_prompt_chat)\n\n        input_payloads = [\n            self._make_payload(idx, prompt_msgs)\n            for idx, prompt_msgs in enumerate(prompts)\n        ]\n        output_payloads = self._api_client.fetch_responses(input_payloads)\n\n        results = []\n        for res in output_payloads:\n            idx = res.metadata[\"index\"]\n            if res.error is not None:\n                logger.error(\n                    f\"Error when processing payload at index {idx}: {res.error}\"\n                )\n                results.append((idx, None, None))\n            else:\n                try:\n                    resp_text = res.response[\"choices\"][0][\"message\"][\"content\"]\n                    choice = get_choice(\n                        text=resp_text,\n                        eval_type=self.eval_type,\n                        match_fn=\"starts_or_endswith\",\n                        choice_strings=self.choice_strings,\n                    )\n                    score = get_choice_score(\n                        choice, self.choice_strings, self.choice_scores\n                    )\n                    results.append((idx, score, resp_text))\n                except Exception as e:\n                    logger.error(\n                        f\"Error when processing payload at index {idx}, not API error: {e}\"\n                    )\n                    results.append((idx, None, None))\n\n        results = sorted(results, key=lambda x: x[0])\n        if isinstance(self.col_out, list):\n            result_scores = [\n                pl.Series(\n                    [val[idx] if val is not None else None for _, val, _ in results]\n                ).alias(self.col_out[idx])\n                for idx in range(len(self.col_out))\n            ]\n            result_scores.extend(\n                [\n                    pl.Series([explanation for _, _, explanation in results]).alias(\n                        self.col_out[idx] + \"_explanation\"\n                    )\n                    for idx in range(len(self.col_out))\n                ]\n            )\n        else:\n            result_scores = [\n                pl.Series([val for _, val, _ in results]).alias(self.col_out),\n                pl.Series([explanation for _, _, explanation in results]).alias(\n                    self.col_out + \"_explanation\"\n                ),\n            ]\n        return {\"output\": data.with_columns(result_scores)}\n</code></pre>"},{"location":"operators/language/OpenAIGradeScore/","title":"OpenAIGradeScore","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator to calculate the grade score of text completions using OpenAI models.</p> <p>Attributes:</p> Name Type Description <code>col_in_input</code> <code>str</code> <p>The name of the input column containing the prompts.</p> <code>col_in_completion</code> <code>str</code> <p>The name of the input column containing the completions.</p> <code>eval_name</code> <code>str</code> <p>The name of the OpenAI evaluation to use.</p> <code>col_out</code> <code>str</code> <p>The name of the output column containing the grade scores.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the calculated grade scores.</p> Source code in <code>uptrain/operators/language/model_grade.py</code> <pre><code>@register_op\nclass OpenAIGradeScore(ColumnOp):\n\"\"\"\n    Operator to calculate the grade score of text completions using OpenAI models.\n\n    Attributes:\n        col_in_input (str): The name of the input column containing the prompts.\n        col_in_completion (str): The name of the input column containing the completions.\n        eval_name (str): The name of the OpenAI evaluation to use.\n        col_out (str): The name of the output column containing the grade scores.\n\n    Returns:\n        dict: A dictionary containing the calculated grade scores.\n\n    \"\"\"\n\n    col_in_input: str = \"prompt\"\n    col_in_completion: str = \"response\"\n    col_out: str = \"openai_grade_score\"\n    eval_name: str\n\n    def setup(self, settings: Settings):\n        self._settings = settings\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        samples = data.select(\n            [\n                pl.col(self.col_in_input).alias(\"input\"),\n                pl.col(self.col_in_completion).alias(\"completion\"),\n            ]\n        )\n        grading_op = OpenaiEval(\n            bundle_path=\"\",\n            completion_name=\"gpt-3.5-turbo\",\n            eval_name=self.eval_name,\n        )\n\n        grading_op.setup(settings=self._settings)\n        oaieval_res = grading_op.run(samples)\n        assert (\n            \"extra\" in oaieval_res\n            and \"metrics\" in oaieval_res[\"extra\"]\n            and \"score\" in oaieval_res[\"extra\"][\"metrics\"]\n        )\n\n        results = pl.Series(oaieval_res[\"extra\"][\"metrics\"][\"score\"])\n        return {\"output\": data.with_columns([results.alias(self.col_out)])}\n</code></pre>"},{"location":"operators/language/OpenaiEval/","title":"OpenaiEval","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator for running OpenAI evals.</p> <p>Attributes:</p> Name Type Description <code>bundle_path</code> <code>str</code> <p>Path to the bundle containing eval resources.</p> <code>completion_name</code> <code>str</code> <p>Name of the completion function to use.</p> <code>eval_name</code> <code>str</code> <p>Name of the eval to run.</p> Source code in <code>uptrain/operators/language/openai_evals.py</code> <pre><code>@register_op\nclass OpenaiEval(ColumnOp):\n\"\"\"\n    Operator for running OpenAI evals.\n\n    Attributes:\n        bundle_path (str): Path to the bundle containing eval resources.\n        completion_name (str): Name of the completion function to use.\n        eval_name (str): Name of the eval to run.\n\n    \"\"\"\n\n    bundle_path: str\n    completion_name: str\n    eval_name: str\n\n    def setup(self, settings: Settings):\n        import openai\n\n        openai.api_key = settings.check_and_get(\"openai_api_key\")\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        registry = evals.registry.Registry()\n        registry_path = os.path.join(self.bundle_path, \"custom_registry\")\n        registry.add_registry_paths([registry_path])\n\n        eval_name = self.eval_name\n        eval_spec = registry.get_eval(eval_name)\n        assert (\n            eval_spec is not None\n        ), f\"Eval {eval_name} not found. Available: {list(sorted(registry._evals.keys()))}\"\n\n        eval_name = eval_spec.key\n        assert eval_name is not None\n\n        # NOTE: create a temporary file with the samples if we are overriding the dataset\n        path_samples_file = f\"/tmp/{uuid.uuid4()}.jsonl\"\n        data.write_ndjson(path_samples_file)\n        eval_spec.args[\"samples_jsonl\"] = path_samples_file  # type: ignore\n\n        # NOTE: add `custom_fns` to the python path\"\n        if self.bundle_path not in sys.path:\n            sys.path.append(self.bundle_path)\n        completion_fns = [self.completion_name]\n        completion_fn_instances = [\n            registry.make_completion_fn(url) for url in completion_fns\n        ]\n\n        run_config = {\n            \"completion_fns\": completion_fns,\n            \"eval_spec\": eval_spec,\n            \"seed\": 42,\n            \"max_samples\": None,\n            \"command\": \"\",\n            \"initial_settings\": {\"visible\": True},\n        }\n        run_spec = evals.base.RunSpec(\n            completion_fns=completion_fns,\n            eval_name=eval_name,\n            base_eval=eval_name.split(\".\")[0],\n            split=eval_name.split(\".\")[1],\n            run_config=run_config,\n            created_by=\"uptrain\",\n        )\n        recorder = UptrainEvalRecorder(run_spec=run_spec)\n\n        eval_class = registry.get_class(eval_spec)\n        extra_eval_params = {}\n        eval = eval_class(\n            completion_fns=completion_fn_instances,\n            seed=42,\n            name=eval_name,\n            registry=registry,\n            **extra_eval_params,\n        )\n        final_report = eval.run(recorder)\n\n        if path_samples_file is not None:\n            os.remove(path_samples_file)\n\n        extra = {\n            \"all_events\": recorder.get_list_events(),\n            \"run_data\": recorder.get_run_data(),\n            \"final_report\": to_py_types(final_report),\n        }\n        unique_types = set(x[\"type\"] for x in recorder.get_list_events())\n        for typ in unique_types:\n            extra[typ] = pl.from_dicts(\n                [\n                    x[\"data\"]\n                    for x in sorted(\n                        recorder.get_list_events(typ),\n                        key=lambda x: int(x[\"sample_id\"].split(\".\")[-1]),\n                    )\n                ]\n            )\n\n        return {\"output\": None, \"extra\": extra}\n</code></pre>"},{"location":"operators/language/PromptEval/","title":"PromptEval","text":"<p>             Bases: <code>TransformOp</code></p> <p>Operator for running prompt-based evaluations.</p> <p>Attributes:</p> Name Type Description <code>prompt_template</code> <code>str</code> <p>Template for the prompt string.</p> <code>prompt_variables</code> <code>list[str]</code> <p>List of variables to substitute in the prompt template.</p> <code>gt_variables</code> <code>list[str]</code> <p>List of ground truth variables.</p> <code>model_name</code> <code>str</code> <p>Name of the model to use for evaluation.</p> <code>col_out_prompt</code> <code>str</code> <p>Output column name for prompts. Defaults to \"prompt\".</p> <code>col_out_response</code> <code>str</code> <p>Output column name for responses. Defaults to \"response\".</p> <code>_settings</code> <code>Settings</code> <p>The framework settings.</p> Source code in <code>uptrain/operators/language/openai_evals.py</code> <pre><code>class PromptEval(TransformOp):\n\"\"\"\n    Operator for running prompt-based evaluations.\n\n    Attributes:\n        prompt_template (str): Template for the prompt string.\n        prompt_variables (list[str]): List of variables to substitute in the prompt template.\n        gt_variables (list[str]): List of ground truth variables.\n        model_name (str): Name of the model to use for evaluation.\n        col_out_prompt (str, optional): Output column name for prompts. Defaults to \"prompt\".\n        col_out_response (str, optional): Output column name for responses. Defaults to \"response\".\n        _settings (Settings): The framework settings.\n\n    \"\"\"\n\n    prompt_template: str\n    prompt_variables: list[str]\n    gt_variables: list[str]\n    model_name: str\n    col_out_prompt: str = \"prompt\"\n    col_out_response: str = \"response\"\n    _settings: Settings\n\n    def setup(self, settings: Settings):\n        self._settings = settings\n        return self\n\n    def _validate_data(self, data: pl.DataFrame) -&gt; None:\n        for col in self.prompt_variables:\n            assert (\n                col in data.columns\n            ), f\"Column for the prompt variable: {col} not found in input data.\"\n        for col in self.gt_variables:\n            assert (\n                col in data.columns\n            ), f\"Column for the ground truth variable: {col} not found in input data.\"\n\n    def _construct_prompts(self, data: pl.DataFrame) -&gt; pl.DataFrame:\n        prompts = [\n            self.prompt_template.format(**{k: row[k] for k in self.prompt_variables})\n            for row in data.rows(named=True)\n        ]\n        return pl.from_dict({\"input\": prompts})\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        self._validate_data(data)\n        prompts = self._construct_prompts(data)\n\n        eval_op = OpenaiEval(\n            bundle_path=os.path.join(UPTRAIN_BASE_DIR, \"openai_eval_custom\"),\n            completion_name=self.model_name,\n            eval_name=\"model_run_all\",\n        )\n\n        eval_op.setup(self._settings)\n        oaieval_res = eval_op.run(prompts)\n        assert \"extra\" in oaieval_res and \"sampling\" in oaieval_res[\"extra\"]\n        results = oaieval_res[\"extra\"][\"sampling\"]\n\n        return {\n            \"output\": data.with_columns(\n                [\n                    pl.Series(results[\"prompt\"]).alias(self.col_out_prompt),\n                    pl.Series(\n                        list(itertools.chain(*results[\"sampled\"])),\n                    ).alias(self.col_out_response),\n                ]\n            )\n        }\n</code></pre>"},{"location":"operators/language/PromptGenerator/","title":"PromptGenerator","text":"<p>             Bases: <code>TransformOp</code></p> <p>Operator to generate text given different prompts/LLM-input-parameters.</p> <p>Attributes:</p> Name Type Description <code>prompt_template</code> <code>str) </code> <p>A string template for the prompt.</p> <code>prompt_params</code> <code>dict[str, list[str]]</code> <p>A dictionary mapping parameter names to lists of values. The cartesian product of all the parameter values will be used to construct the prompts.</p> <code>models</code> <code>list[str]</code> <p>A list of models to run the experiment on.</p> <code>context_vars</code> <code>Union[list[str], dict[str, str]]</code> <p>A dictionary mapping context variable names to corresponding columns in the input dataset.</p> <code>col_out_prefix</code> <code>str</code> <p>Prefix for the output columns.</p> Source code in <code>uptrain/operators/language/generation.py</code> <pre><code>@register_op\nclass PromptGenerator(TransformOp):\n\"\"\"Operator to generate text given different prompts/LLM-input-parameters.\n\n    Attributes:\n        prompt_template (str) : A string template for the prompt.\n        prompt_params (dict[str, list[str]]): A dictionary mapping parameter names to lists of values.\n            The cartesian product of all the parameter values will be used to\n            construct the prompts.\n        models (list[str]): A list of models to run the experiment on.\n        context_vars (Union[list[str], dict[str, str]]): A dictionary mapping context variable names to corresponding\n            columns in the input dataset.\n        col_out_prefix (str): Prefix for the output columns.\n\n    \"\"\"\n\n    prompt_template: str\n    prompt_params: dict[str, list[str]]\n    models: list[str]\n    context_vars: t.Union[list[str], dict[str, str]]\n    col_out_prefix: str = \"exp_\"\n\n    def setup(self, settings: \"Settings\"):\n        self._settings = settings\n        if isinstance(self.context_vars, list):\n            self.context_vars = dict(zip(self.context_vars, self.context_vars))\n        return self\n\n\"\"\"Construct all the prompt variations and generate completions for each.\"\"\"\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        list_params = []\n        for experiment_id, combo in enumerate(\n            itertools.product(*self.prompt_params.values(), self.models)\n        ):\n            prompt_params, model = combo[:-1], combo[-1]\n            variables = dict(zip(self.prompt_params.keys(), prompt_params))\n            list_params.append(\n                {\n                    \"template\": self.prompt_template,\n                    self.col_out_prefix + \"model\": model,\n                    **{self.col_out_prefix + k: v for k, v in variables.items()},\n                    self.col_out_prefix + \"experiment_id\": experiment_id,\n                }\n            )\n        params_dataset = pl.DataFrame(list_params)\n\n        # Do a cross join of the input with the params dataset to get all the\n        # inputs for the completion step\n        input_dataset = data.join(params_dataset, on=None, how=\"cross\")\n\n        # construct the prompts by iterating over the rows of the input dataset and\n        # formatting the prompt template with the row values\n        prompts = []\n        for row in input_dataset.iter_rows(named=True):\n            fill = {k: row[v] for k, v in self.context_vars.items()}\n            fill.update(\n                {k: row[self.col_out_prefix + k] for k in self.prompt_params.keys()}\n            )\n\n            # TODO: Temp Fix for handling json in prompts. Permanent fix is to integrate langchain?\n            try:\n                prompt = row[\"template\"].format(**fill)\n            except:\n                prompt = row[\"template\"]\n                for k, v in fill.items():\n                    prompt = prompt.replace(\"{{\" + k + \"}}\", v)\n            prompts.append(prompt)\n\n        input_w_prompts = input_dataset.with_columns(\n            [pl.Series(self.col_out_prefix + \"prompt\", prompts)]\n        )\n        return {\"output\": input_w_prompts}\n</code></pre>"},{"location":"operators/language/RougeScore/","title":"RougeScore","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator to compare a generated text with a source text using the Rouge score metric.</p> <p>Attributes:</p> Name Type Description <code>score_type</code> <code>Literal['precision', 'recall', 'f1']</code> <p>The type of Rouge score to calculate.</p> <code>col_in_generated</code> <code>str</code> <p>The name of the input column containing the generated text.</p> <code>col_in_source</code> <code>str</code> <p>The name of the input column containing the source text.</p> <code>col_out</code> <code>str</code> <p>The name of the output column containing the Rouge scores.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the Rouge scores for each pair of generated and source text.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import RougeScore\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"text_generated\": [\"This is the generated text.\", \"Another generated sentence.\"],\n    \"text_source\": [\"This is the original source text.\", \"This is a different source text.\"]\n})\n\n# Create an instance of the RougeScore class\nrouge_op = RougeScore(score_type=\"f1\")\n\n# Calculate the Rouge-L scores\nscores = rouge_op.run(df)[\"output\"]\n\n# Print the Rouge-L scores\nprint(scores)\n</code></pre> Output <pre><code>shape: (2,)\nSeries: '_col_0' [i64]\n[\n        72\n        0\n]\n</code></pre> Source code in <code>uptrain/operators/language/rouge.py</code> <pre><code>@register_op\nclass RougeScore(ColumnOp):\n\"\"\"\n    Operator to compare a generated text with a source text using the Rouge score metric.\n\n    Attributes:\n        score_type (Literal[\"precision\", \"recall\", \"f1\"]): The type of Rouge score to calculate.\n        col_in_generated (str): The name of the input column containing the generated text.\n        col_in_source (str): The name of the input column containing the source text.\n        col_out (str): The name of the output column containing the Rouge scores.\n\n    Returns:\n        dict: A dictionary containing the Rouge scores for each pair of generated and source text.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import RougeScore\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"text_generated\": [\"This is the generated text.\", \"Another generated sentence.\"],\n            \"text_source\": [\"This is the original source text.\", \"This is a different source text.\"]\n        })\n\n        # Create an instance of the RougeScore class\n        rouge_op = RougeScore(score_type=\"f1\")\n\n        # Calculate the Rouge-L scores\n        scores = rouge_op.run(df)[\"output\"]\n\n        # Print the Rouge-L scores\n        print(scores)\n        ```\n\n    Output:\n        ```\n        shape: (2,)\n        Series: '_col_0' [i64]\n        [\n                72\n                0\n        ]\n        ```\n\n    \"\"\"\n\n    score_type: t.Literal[\"precision\", \"recall\", \"f1\"]\n    col_in_generated: str = \"text_generated\"\n    col_in_source: str = \"text_source\"\n    col_out: str = \"rouge_score\"\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        text_generated = data.get_column(self.col_in_generated)\n        text_source = data.get_column(self.col_in_source)\n\n        results = []\n        scores = []\n        for i in range(len(text_generated)):\n            scorer = rouge_scorer.RougeScorer([\"rougeL\"])  # type: ignore\n            if text_source[i] is None or text_generated[i] is None:\n                scores.append({\"rougeL\": (0, 0, 0)})\n            else:\n                scores.append(scorer.score(text_source[i], text_generated[i]))\n\n        type_to_index = {\"precision\": 0, \"recall\": 1, \"f1\": 2}\n        if self.score_type not in type_to_index:\n            raise Exception(f\"{self.score_type} not implemented\")\n        else:\n            score_index = type_to_index[self.score_type]\n\n        results = pl.Series([int(x[\"rougeL\"][score_index] * 100) for x in scores])\n        return {\"output\": data.with_columns([results.alias(self.col_out)])}\n</code></pre>"},{"location":"operators/language/TextComparison/","title":"TextComparison","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator to compare each text entry in a column with a list of reference texts.</p> <p>Attributes:</p> Name Type Description <code>reference_texts</code> <code>Union[list[str], str]</code> <p>List of reference text for comparison.</p> <code>col_in_text</code> <code>str</code> <p>The name of the input column containing the text data.</p> <code>col_out</code> <code>str</code> <p>The name of the output column containing the comparison results.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the comparison results (1 if equal, 0 otherwise).</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import TextComparison\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"text\": [\"This is a sample text.\", \"Another example sentence.\", \"Yet another sentence.\"]\n})\n\n# Set the reference text for comparison\nref_text = [\"This is a sample text.\", \"Yet another sentence.\"]\n\n# Create an instance of the TextComparison class\ncomp_op = TextComparison(reference_texts=ref_text, col_in_text=\"text\")\n\n# Compare each text entry with the reference text\ncomparison = comp_op.run(df)[\"output\"]\n\n# Print the comparison results\nprint(comparison)\n</code></pre> Output <pre><code>shape: (3,)\nSeries: '_col_0' [i64]\n[\n        1\n        0\n        1\n]\n</code></pre> Source code in <code>uptrain/operators/language/text.py</code> <pre><code>@register_op\nclass TextComparison(ColumnOp):\n\"\"\"\n    Operator to compare each text entry in a column with a list of reference texts.\n\n    Attributes:\n        reference_texts (Union[list[str], str]): List of reference text for comparison.\n        col_in_text (str): The name of the input column containing the text data.\n        col_out (str): The name of the output column containing the comparison results.\n\n    Returns:\n        dict: A dictionary containing the comparison results (1 if equal, 0 otherwise).\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import TextComparison\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"text\": [\"This is a sample text.\", \"Another example sentence.\", \"Yet another sentence.\"]\n        })\n\n        # Set the reference text for comparison\n        ref_text = [\"This is a sample text.\", \"Yet another sentence.\"]\n\n        # Create an instance of the TextComparison class\n        comp_op = TextComparison(reference_texts=ref_text, col_in_text=\"text\")\n\n        # Compare each text entry with the reference text\n        comparison = comp_op.run(df)[\"output\"]\n\n        # Print the comparison results\n        print(comparison)\n        ```\n\n    Output:\n        ```\n        shape: (3,)\n        Series: '_col_0' [i64]\n        [\n                1\n                0\n                1\n        ]\n        ```\n\n    \"\"\"\n\n    reference_texts: t.Union[list[str], str]\n    col_in_text: str\n    col_out: str = \"text_comparison\"\n\n    def setup(self, settings: Settings):\n        if isinstance(self.reference_texts, str):\n            self.reference_texts = [self.reference_texts]\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        results = data.get_column(self.col_in_text).apply(\n            lambda x: int(sum([x == y for y in self.reference_texts]))\n        )\n        return {\"output\": data.with_columns([results.alias(self.col_out)])}\n</code></pre>"},{"location":"operators/language/TextCompletion/","title":"TextCompletion","text":"<p>             Bases: <code>TransformOp</code></p> <p>Takes a table of prompts and LLM model to use, generates output text.</p> <p>Attributes:</p> Name Type Description <code>col_in_prompt</code> <code>str</code> <p>The name of the column containing the prompt template.</p> <code>col_in_model</code> <code>str</code> <p>The name of the column containing the model name.</p> <code>col_out_completion</code> <code>str</code> <p>The name of the column containing the generated text.</p> <code>temperature</code> <code>float</code> <p>Temperature for the LLM to generate responses.</p> <p>Returns:</p> Name Type Description <code>TYPE_TABLE_OUTPUT</code> <p>A dictionary containing the dataset with the output text.</p> Source code in <code>uptrain/operators/language/generation.py</code> <pre><code>@register_op\nclass TextCompletion(TransformOp):\n\"\"\"\n    Takes a table of prompts and LLM model to use, generates output text.\n\n    Attributes:\n        col_in_prompt (str): The name of the column containing the prompt template.\n        col_in_model (str): The name of the column containing the model name.\n        col_out_completion (str): The name of the column containing the generated text.\n        temperature (float): Temperature for the LLM to generate responses.\n\n    Returns:\n        TYPE_TABLE_OUTPUT: A dictionary containing the dataset with the output text.\n    \"\"\"\n\n    col_in_prompt: str = \"prompt\"\n    col_in_model: str = \"model\"\n    col_out_completion: str = \"generated\"\n    temperature: float = 1.0\n    _api_client: LLMMulticlient\n\n    def setup(self, settings: Settings):\n        self._api_client = LLMMulticlient(settings=settings)\n        return self\n\n    def _make_payload(self, id: t.Any, text: str, model: str) -&gt; Payload:\n        return Payload(\n            endpoint=\"chat.completions\",\n            data={\n                \"model\": model,\n                \"messages\": [{\"role\": \"user\", \"content\": text}],\n                \"temperature\": self.temperature,\n            },\n            metadata={\"index\": id},\n        )\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        prompt_ser = data.get_column(self.col_in_prompt)\n        model_ser = data.get_column(self.col_in_model)\n        input_payloads = [\n            self._make_payload(idx, text, model)\n            for idx, (text, model) in enumerate(zip(prompt_ser, model_ser))\n        ]\n        output_payloads = self._api_client.fetch_responses(input_payloads)\n\n        results = []\n        for res in output_payloads:\n            assert (\n                res is not None\n            ), \"Response should not be None, we should've handled exceptions beforehand.\"\n            idx = res.metadata[\"index\"]\n            if res.error is not None:\n                logger.error(\n                    f\"Error when processing payload at index {idx}: {res.error}\"\n                )\n                results.append((idx, None))\n            else:\n                resp_text = res.response[\"choices\"][0][\"message\"][\"content\"]\n                results.append((idx, resp_text))\n\n        output_text = pl.Series(\n            values=[val for _, val in sorted(results, key=lambda x: x[0])]\n        )\n        return {\n            \"output\": data.with_columns([output_text.alias(self.col_out_completion)])\n        }\n</code></pre>"},{"location":"operators/language/TextLength/","title":"TextLength","text":"<p>             Bases: <code>ColumnOp</code></p> <p>Operator to calculate the length of each text entry in a column.</p> <p>Attributes:</p> Name Type Description <code>col_in_text</code> <code>str</code> <p>The name of the input column containing the text data.</p> <code>col_out</code> <code>str</code> <p>The name of the output column containing the text lengths.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the calculated text lengths.</p> Example <pre><code>import polars as pl\nfrom uptrain.operators import TextLength\n\n# Create a DataFrame\ndf = pl.DataFrame({\n    \"text\": [\"This is a sample text.\", \"Another example sentence.\", \"Yet another sentence.\"]\n})\n\n# Create an instance of the TextLength class\nlength_op = TextLength(col_in_text=\"text\")\n\n# Calculate the length of each text entry\nlengths = length_op.run(df)[\"output\"]\n\n# Print the text lengths\nprint(lengths)\n</code></pre> Output <pre><code>shape: (3,)\nSeries: '_col_0' [i64]\n[\n        22\n        25\n        21\n]\n</code></pre> Source code in <code>uptrain/operators/language/text.py</code> <pre><code>@register_op\nclass TextLength(ColumnOp):\n\"\"\"\n    Operator to calculate the length of each text entry in a column.\n\n    Attributes:\n        col_in_text (str): The name of the input column containing the text data.\n        col_out (str): The name of the output column containing the text lengths.\n\n    Returns:\n        dict: A dictionary containing the calculated text lengths.\n\n    Example:\n        ```\n        import polars as pl\n        from uptrain.operators import TextLength\n\n        # Create a DataFrame\n        df = pl.DataFrame({\n            \"text\": [\"This is a sample text.\", \"Another example sentence.\", \"Yet another sentence.\"]\n        })\n\n        # Create an instance of the TextLength class\n        length_op = TextLength(col_in_text=\"text\")\n\n        # Calculate the length of each text entry\n        lengths = length_op.run(df)[\"output\"]\n\n        # Print the text lengths\n        print(lengths)\n        ```\n\n    Output:\n        ```\n        shape: (3,)\n        Series: '_col_0' [i64]\n        [\n                22\n                25\n                21\n        ]\n        ```\n\n    \"\"\"\n\n    col_in_text: str\n    col_out: str = \"text_length\"\n\n    def setup(self, settings: Settings):\n        return self\n\n    def run(self, data: pl.DataFrame) -&gt; TYPE_TABLE_OUTPUT:\n        results = data.get_column(self.col_in_text).apply(len)\n        return {\"output\": data.with_columns([results.alias(self.col_out)])}\n</code></pre>"}]}